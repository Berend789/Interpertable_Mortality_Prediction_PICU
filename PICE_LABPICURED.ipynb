{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3b7e431a861a72513f361682db481bb043ab213b57189a56d42fe6b32fa57c58"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.impute as skin\n",
    "from sqlalchemy import create_engine\n",
    "import locale\n",
    "import os\n",
    "locale.setlocale(locale.LC_ALL,'fr_FR')\n",
    "output_folder=r\"C:\\Users\\berend\\Documents\\Python_Scripts\\vrije_stage\\Results_uncertainty\"\n",
    "hour=6\n",
    "from all_own_functions import cnfl,value_filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3170: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from All_standard_variables import conv_dict, dtype_dict\n",
    "# Used columns from database\n",
    "lab_cols=['pat_bd','pat_datetime','lab_bl_b2m', 'lab_bl_bil_d', 'lab_bl_bil_i', 'lab_bl_ca2', 'lab_bl_catot', 'lab_bl_cc', 'lab_bl_cl', 'lab_bl_cr', 'lab_bl_CRP', 'lab_bl_f', 'lab_bl_gluc', 'lab_bl_hb', 'lab_bl_ht', 'lab_bl_k', 'lab_bl_lactate', 'lab_bl_leuco', 'lab_bl_mg', 'lab_bl_na', 'lab_bl_tr', 'lab_bl_ur', 'pat_hosp_id', 'Status']\n",
    "# datetime columns\n",
    "pars_dates=['pat_bd','pat_datetime']\n",
    "# read in data as dataframe (kind of table with an index)\n",
    "df=pd.read_csv(f\"total_database_{hour}hour.csv\",delimiter=';',usecols=lab_cols,header=0,converters=conv_dict,parse_dates=pars_dates)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "if 'pat_bd' in list(df.columns):\n",
    "    df.replace(to_replace='NULL', value=np.nan,inplace=True)            # Replace NULL with NaN\n",
    "    df=value_filtering(df)                                              # Delete all rows with no values\n",
    "    df['pat_datetime_temp']=pd.to_datetime(df['pat_datetime']).dt.date  # set datetime object to days object\n",
    "    df['pat_bd']=pd.to_datetime(df['pat_bd']).dt.date                   # Same as above\n",
    "    df['Age'] = (df['pat_datetime_temp'] - df['pat_bd']).dt.days        # Calculate age\n",
    "    df['Age']=df['Age'].divide(365)                                     # Calculate age in years\n",
    "    df=df.drop('pat_datetime_temp',axis=1)                              # Remove obsolete columns\n",
    "    df=df.drop('pat_datetime',axis=1)\n",
    "    df=df.drop('pat_bd',axis=1)\n",
    "df['pat_hosp_id'] = df['pat_hosp_id'].astype('int')                     # Set patientnumber as integer instead of float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:993: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1370: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input, interpolation=interpolation\n",
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:993: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1370: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input, interpolation=interpolation\n",
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:993: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1370: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input, interpolation=interpolation\n",
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:993: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1370: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input, interpolation=interpolation\n",
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:993: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1370: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input, interpolation=interpolation\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3628846 entries, 0 to 3628845\n",
      "Data columns (total 23 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   pat_hosp_id     int32  \n",
      " 1   lab_bl_b2m      float64\n",
      " 2   lab_bl_bil_d    float64\n",
      " 3   lab_bl_bil_i    float64\n",
      " 4   lab_bl_ca2      float64\n",
      " 5   lab_bl_catot    float64\n",
      " 6   lab_bl_cc       float64\n",
      " 7   lab_bl_cl       float64\n",
      " 8   lab_bl_cr       float64\n",
      " 9   lab_bl_CRP      float64\n",
      " 10  lab_bl_f        float64\n",
      " 11  lab_bl_gluc     float64\n",
      " 12  lab_bl_hb       float64\n",
      " 13  lab_bl_ht       float64\n",
      " 14  lab_bl_k        float64\n",
      " 15  lab_bl_lactate  float64\n",
      " 16  lab_bl_leuco    float64\n",
      " 17  lab_bl_mg       float64\n",
      " 18  lab_bl_na       float64\n",
      " 19  lab_bl_tr       float64\n",
      " 20  lab_bl_ur       float64\n",
      " 21  Status          object \n",
      " 22  Age             int32  \n",
      "dtypes: float64(20), int32(2), object(1)\n",
      "memory usage: 636.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "\n",
    "class Wraptastic:\n",
    "    \"\"\"\n",
    "    Class of functions to apply sklearn transformers (i.e. RobustScaler) while remaininig the dataframe structure of the variable instead of an array\n",
    "    \"\"\"\n",
    "    def __init__(self, transform: typing.Callable):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, df):\n",
    "        transformed = self.transform.fit_transform(df.values)\n",
    "        return pd.DataFrame(data=transformed, columns=df.columns, index=df.index)\n",
    "\n",
    "# Categorise Age\n",
    "if any(df['Age'] > 12) == True:\n",
    "    df.loc[(df['Age'] > 12),'Age']=50\n",
    "    df.loc[(df['Age'] <= 12) & (df['Age'] > 4),'Age']=51\n",
    "    df.loc[(df['Age'] > 1) & (df['Age'] <=4),'Age']=52\n",
    "    df.loc[(df['Age'] > 0.5)  & (df['Age'] <=1),'Age']=53\n",
    "    df.loc[(df['Age'] <= 0.5),'Age']=54\n",
    "    df['Age'] = df['Age'].subtract(50)\n",
    "    df['Age'] = df['Age'].astype('int32')\n",
    "\n",
    "# Select numerical columns for scaling\n",
    "float_columns=list(df.select_dtypes(include=['float64','float32','int32']).columns)\n",
    "\n",
    "ss=Wraptastic(RobustScaler())\n",
    "float_columns.remove('pat_hosp_id') # No use of scaling patient numbers\n",
    "\n",
    "df_temp=df[float_columns]\n",
    "df_temp=(df_temp.groupby('Age',sort=False).apply(ss).drop('Age',axis=\"columns\")) # apply scaling to the Age categories\n",
    "float_columns.remove('Age') # No use of scaling the age categories\n",
    "df[float_columns]=df_temp\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.descriptivestats import sign_test\n",
    "from tsfresh.feature_extraction.feature_calculators import abs_energy,number_cwt_peaks\n",
    "from all_own_functions import fft_feat\n",
    "\n",
    "def lab_values_feature_building(dfl,columns,pat):\n",
    "    \"\"\"\"\n",
    "    Function which calculates the specific features per variable per patient in the dataframe\n",
    "    Function selects variables based on type of feature (i.e. float/object)\n",
    "     \"\"\"\n",
    "    group=dfl\n",
    "    df=pd.DataFrame()\n",
    "    if 'work' in columns:\n",
    "        group['work']=WOB_calc(group)\n",
    "        group['hr_rr_ratio']=hr_rr_ratio(group)\n",
    "    for colum in columns:\n",
    "        if (group[colum].dtypes == float):\n",
    "            temp=pd.DataFrame(group[colum].describe().to_numpy()[None], # Calculating the descriptive statistics for numerical variables\n",
    "            columns=[colum+'_count',colum+'_mean',colum+'_std',colum+'_min',colum+'_25%',colum+'_50%',colum+ '_75%',colum+'_max'],index=[pat]) # Naming columns\n",
    "            l=[colum+'_count',colum+'_std',colum+'_max']\n",
    "            temp=temp[l]\n",
    "            #skew=pd.Series(group[colum].skew(),name=(colum+'_skew'))\n",
    "            #kurt=pd.Series(group[colum].kurtosis(),name=(colum+'_kurtosis'))\n",
    "            #high_mean=pd.Series(sign_test(group[colum],mu0=group[colum].mean()),name=(colum+'_count_above_mean'))       # counts above mean\n",
    "            #high_median=pd.Series(sign_test(group[colum],mu0=group[colum].median()),name=(colum+'_count_above_median')) # counts above median\n",
    "            #abs_energy=pd.Series(abs_energy(group[colum]),name=(colum+'_abs_energy'))                                   # Absolute energy of the signal\n",
    "            #cwt_peaks=pd.Series(abs_energy(group[colum]),name=(colum+'_number_CWT_peaks'))                              # Amount of peaks in the continuous wavelet analysis\n",
    "            #fft_aggr=fft_feat(group[colum],pat,colum)                                                                   # Descriptive statistics in the frequency domain\n",
    "            df=pd.concat([temp,df],axis=1)\n",
    "            #df.append(skew)\n",
    "            #df.append(kurt)\n",
    "            #df.append(high_mean)\n",
    "            #df.append(high_median)\n",
    "            #df.append(cwt_peaks)\n",
    "            #df.append(fft_aggr)\n",
    "        elif (group[colum].dtypes == object):\n",
    "\n",
    "            temp=pd.DataFrame(group[colum].describe().to_numpy()[None],  #calculating the descriptive statistics for categorical variables\n",
    "            columns=[colum+'_count',colum+'_unique',colum+'_top',colum+'_freq'],index=[pat])\n",
    "            \n",
    "            df=pd.concat([temp,df],axis=1)\n",
    "        else:\n",
    "            temp=pd.DataFrame(group[colum].describe(datetime_is_numeric=True)['max'], # Calculating the descriptive statistics for the other variables\n",
    "            columns=[colum+'_max'],index=[pat])  #[colum+'_count',colum+'_mean',colum+'_min',colum+'_25%',colum+'_50%',colum+'_75%',colum+ '_max'],index=[pat])\n",
    "            df=pd.concat([temp,df],axis=1)\n",
    "        del temp        \n",
    "    return df     \n",
    "    \n",
    "def population_descriptives(df,columns):\n",
    "    \"\"\"\n",
    "    Calculate the features based from the whole population/ dataframe\n",
    "    Takes in the columns from which the features need to be calculated\n",
    "    Also adds a for currrent status\n",
    "    \"\"\"\n",
    "    grouped = df.groupby('pat_hosp_id',sort=False)                              # group dataframe per patient\n",
    "    df_feat=grouped.get_group((list(grouped.groups)[0]))                        # get first patient\n",
    "    df_feat=lab_values_feature_building(df_feat,columns,df_feat['pat_hosp_id'].iloc[0]) # calculate features for one patient (needed for intial dataframe for append function)\n",
    "    for pat,group in grouped:        \n",
    "        df_temp = lab_values_feature_building(group,columns,pat)                # loop over all patients\n",
    "        if 'Death' in group['Status'].unique():                                 #add label for deceased patients\n",
    "            df_temp['Label']='Death'\n",
    "        else:\n",
    "            df_temp['Label']='Alive'\n",
    "        df_feat=df_feat.append(df_temp)                                         # append dataframe with total dataframe\n",
    "        del df_temp\n",
    "    return df_feat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 6743 entries, 1936 to 9996691\nData columns (total 62 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   Age_max               6743 non-null   float64\n 1   lab_bl_ur_count       6743 non-null   float64\n 2   lab_bl_ur_std         453 non-null    float64\n 3   lab_bl_ur_max         1301 non-null   float64\n 4   lab_bl_tr_count       6743 non-null   float64\n 5   lab_bl_tr_std         1094 non-null   float64\n 6   lab_bl_tr_max         2853 non-null   float64\n 7   lab_bl_na_count       6743 non-null   float64\n 8   lab_bl_na_std         3792 non-null   float64\n 9   lab_bl_na_max         5228 non-null   float64\n 10  lab_bl_mg_count       6743 non-null   float64\n 11  lab_bl_mg_std         494 non-null    float64\n 12  lab_bl_mg_max         1530 non-null   float64\n 13  lab_bl_leuco_count    6743 non-null   float64\n 14  lab_bl_leuco_std      658 non-null    float64\n 15  lab_bl_leuco_max      1699 non-null   float64\n 16  lab_bl_lactate_count  6743 non-null   float64\n 17  lab_bl_lactate_std    1770 non-null   float64\n 18  lab_bl_lactate_max    3073 non-null   float64\n 19  lab_bl_k_count        6743 non-null   float64\n 20  lab_bl_k_std          3794 non-null   float64\n 21  lab_bl_k_max          5228 non-null   float64\n 22  lab_bl_ht_count       6743 non-null   float64\n 23  lab_bl_ht_std         3999 non-null   float64\n 24  lab_bl_ht_max         5295 non-null   float64\n 25  lab_bl_hb_count       6743 non-null   float64\n 26  lab_bl_hb_std         4021 non-null   float64\n 27  lab_bl_hb_max         5303 non-null   float64\n 28  lab_bl_gluc_count     6743 non-null   float64\n 29  lab_bl_gluc_std       3853 non-null   float64\n 30  lab_bl_gluc_max       5259 non-null   float64\n 31  lab_bl_f_count        6743 non-null   float64\n 32  lab_bl_f_std          174 non-null    float64\n 33  lab_bl_f_max          413 non-null    float64\n 34  lab_bl_CRP_count      6743 non-null   float64\n 35  lab_bl_CRP_std        443 non-null    float64\n 36  lab_bl_CRP_max        1223 non-null   float64\n 37  lab_bl_cr_count       6743 non-null   float64\n 38  lab_bl_cr_std         487 non-null    float64\n 39  lab_bl_cr_max         1378 non-null   float64\n 40  lab_bl_cl_count       6743 non-null   float64\n 41  lab_bl_cl_std         233 non-null    float64\n 42  lab_bl_cl_max         692 non-null    float64\n 43  lab_bl_cc_count       6743 non-null   float64\n 44  lab_bl_cc_std         2 non-null      float64\n 45  lab_bl_cc_max         3 non-null      float64\n 46  lab_bl_catot_count    6743 non-null   float64\n 47  lab_bl_catot_std      100 non-null    float64\n 48  lab_bl_catot_max      289 non-null    float64\n 49  lab_bl_ca2_count      6743 non-null   float64\n 50  lab_bl_ca2_std        3603 non-null   float64\n 51  lab_bl_ca2_max        5078 non-null   float64\n 52  lab_bl_bil_i_count    6743 non-null   float64\n 53  lab_bl_bil_i_std      175 non-null    float64\n 54  lab_bl_bil_i_max      384 non-null    float64\n 55  lab_bl_bil_d_count    6743 non-null   float64\n 56  lab_bl_bil_d_std      113 non-null    float64\n 57  lab_bl_bil_d_max      250 non-null    float64\n 58  lab_bl_b2m_count      6743 non-null   float64\n 59  lab_bl_b2m_std        0 non-null      float64\n 60  lab_bl_b2m_max        0 non-null      float64\n 61  Label                 6743 non-null   object \ndtypes: float64(61), object(1)\nmemory usage: 3.2+ MB\nNone\n      Age_max  lab_bl_ur_count  lab_bl_ur_std  lab_bl_ur_max  lab_bl_tr_count  \\\n1936      0.0              0.0            NaN            NaN              0.0   \n2171      0.0              1.0            NaN      -0.111111              1.0   \n2626      1.0              0.0            NaN            NaN              1.0   \n5291      2.0              0.0            NaN            NaN              0.0   \n5325      1.0              1.0            NaN      -0.254546              2.0   \n\n      lab_bl_tr_std  lab_bl_tr_max  lab_bl_na_count  lab_bl_na_std  \\\n1936            NaN            NaN              1.0            NaN   \n2171            NaN      -0.904762              4.0       0.125000   \n2626            NaN      -1.332258              3.0      15.992915   \n5291            NaN            NaN              6.0      19.170290   \n5325        0.04562       0.106452              4.0      13.637571   \n\n      lab_bl_na_max  ...  lab_bl_bil_i_count  lab_bl_bil_i_std  \\\n1936          -1.50  ...                 0.0               NaN   \n2171          -0.50  ...                 0.0               NaN   \n2626           0.00  ...                 0.0               NaN   \n5291           0.25  ...                 0.0               NaN   \n5325          -0.20  ...                 1.0               NaN   \n\n      lab_bl_bil_i_max  lab_bl_bil_d_count  lab_bl_bil_d_std  \\\n1936               NaN                 0.0               NaN   \n2171               NaN                 0.0               NaN   \n2626               NaN                 0.0               NaN   \n5291               NaN                 0.0               NaN   \n5325          0.833333                 1.0               NaN   \n\n      lab_bl_bil_d_max  lab_bl_b2m_count  lab_bl_b2m_std  lab_bl_b2m_max  \\\n1936               NaN               0.0             NaN             NaN   \n2171               NaN               0.0             NaN             NaN   \n2626               NaN               0.0             NaN             NaN   \n5291               NaN               0.0             NaN             NaN   \n5325          -0.30625               0.0             NaN             NaN   \n\n      Label  \n1936  Alive  \n2171  Alive  \n2626  Alive  \n5291  Alive  \n5325  Alive  \n\n[5 rows x 62 columns]\nAlive    6452\nDeath     291\nName: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_list=(list(df.columns))                                        # specifying which columns need to be taken into account\n",
    "column_list.remove('Status')    \n",
    "column_list.remove('pat_hosp_id')\n",
    "df_try_full=population_descriptives(df,column_list)                   # using function described above\n",
    "df_try_full = df_try_full[~df_try_full.index.duplicated(keep='last')] # eliminate double patients (first patient is calculated double)\n",
    "print(df_try_full.info())                                             # show the dataframe\n",
    "print(df_try_full.head())\n",
    "print(df_try_full['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "pdf=PdfPages('Scatterplots_lab.pdf')\n",
    "for column in list(df.columns):\n",
    "    try:\n",
    "        sns.scatterplot(data=df_try_full,x=column+'_max',y=column+\"_count\",hue='Label',style='Age_max')\n",
    "        plt.title(f'Scatterplot of count and max value of {column}')\n",
    "        plt.legend(loc=1,fontsize='xx-small')\n",
    "        fig=plt.gcf()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "        sns.scatterplot(data=df_try_full,x=column+'_std',y=column+\"_count\",hue='Label',style='Age_max')\n",
    "        plt.title(f'Scatterplot of count and min value of {column}')\n",
    "        plt.legend(loc=1,fontsize='xx-small')\n",
    "        fig=plt.gcf()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "    except ValueError:\n",
    "        print(column)\n",
    "pdf.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nFloat64Index: 13791 entries, 219.0 to 526480713.0\nData columns (total 42 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   AdmissionDate             13791 non-null  object \n 1   Age(days)                 13791 non-null  float64\n 2   RiskDiagnoses             13791 non-null  object \n 3   Urgency                   13791 non-null  object \n 4   Recovery                  13791 non-null  object \n 5   Ventilated                13791 non-null  object \n 6   AdmissionPupils           13187 non-null  float64\n 7   SystolicBP                11269 non-null  float64\n 8   BaseExcess                6433 non-null   float64\n 9   FiO2                      6815 non-null   float64\n 10  PaO2                      5739 non-null   float64\n 11  PIM2Score                 13791 non-null  float64\n 12  PIM2Mort                  13791 non-null  float64\n 13  PIM3Score                 13791 non-null  float64\n 14  PIM3Mort                  13791 non-null  float64\n 15  AdmissionSource           13791 non-null  object \n 16  Cancer                    13791 non-null  object \n 17  CPR24HourBefore           13791 non-null  object \n 18  CreatinineMax             441 non-null    float64\n 19  GlucoseMax                1346 non-null   float64\n 20  HeartRateMax              1682 non-null   float64\n 21  LowRiskPrimary            13791 non-null  object \n 22  MentalStatus              0 non-null      float64\n 23  PaO2Min                   5739 non-null   float64\n 24  PCO2Max                   1322 non-null   float64\n 25  PHMin                     686 non-null    float64\n 26  PHMax                     686 non-null    float64\n 27  PlateletsMin              605 non-null    float64\n 28  PotassiumMax              1319 non-null   float64\n 29  PTMax                     181 non-null    float64\n 30  PTTMax                    179 non-null    float64\n 31  PupilsFixed               13187 non-null  float64\n 32  SystolicBloodPressureMin  11269 non-null  float64\n 33  TemperatureMin            1182 non-null   float64\n 34  TemperatureMax            1171 non-null   float64\n 35  BicarbonateMin            1317 non-null   float64\n 36  BicarbonateMax            1317 non-null   float64\n 37  UreaMax                   394 non-null    float64\n 38  WhiteBloodCountMin        367 non-null    float64\n 39  PRISM3Neuro               13791 non-null  float64\n 40  PRISM3Score               13791 non-null  float64\n 41  PRISM4Mortality           13791 non-null  float64\ndtypes: float64(33), object(9)\nmemory usage: 4.8+ MB\nNone\n"
     ]
    }
   ],
   "source": [
    "# specify datatypes for loading data\n",
    "# cnfl is function for converting strings to floats\n",
    "conv_pice={'BaseExcess':cnfl,'FiO2':cnfl,'PaO2':cnfl,'PIM2Score':cnfl,'PIM2Mort':cnfl,'PIM3Score':cnfl,\n",
    "'PIM3Mort':cnfl,'GlucoseMax':cnfl,'PaO2Min':cnfl,'PCO2Max':cnfl,'PHMax':cnfl,'PHMin':cnfl,'PotassiumMax':cnfl,'PTMax':cnfl,'TemperatureMax':cnfl,'TemperatureMin':cnfl,\n",
    "'BicarbonateMin':cnfl,'BicarbonateMax':cnfl,'UreaMax':cnfl,'WhiteBloodCountMin':cnfl,'PRISM4Mortality':cnfl,'Age(days)':cnfl}\n",
    "\n",
    "df_pice=pd.read_csv('scores.csv',converters=conv_pice,header=0,delimiter=';') # load in data\n",
    "\n",
    "df_pice.drop(df_pice.tail(2).index,inplace=True)                              # drop last column which is not a patient\n",
    "df_pice.dropna(axis=0,how='all',inplace=True)                                 # drop all rows with only NaN\n",
    "#del df_pice['AdmissionDate']                                                  # Admission data is deemed not relevant\n",
    "\n",
    "index_names = df_pice[df_pice['HospitalNumber'] == 'RPH'].index               # remove column with RPH as patientnumber\n",
    "df_pice.drop(index_names, inplace=True)\n",
    "\n",
    "# identifying duplicate patients                                    \n",
    "a=df_pice[df_pice['HospitalNumber'].duplicated(keep=False)]                   \n",
    "a=a[a['HospitalNumber'].duplicated(keep='first')]\n",
    "duplicate_patients=a['HospitalNumber'].tolist()\n",
    "\n",
    "# set patientnumber as index\n",
    "df_pice=df_pice.set_index('HospitalNumber')                                  \n",
    "df_pice=df_pice.sort_index()\n",
    "\n",
    "\n",
    "# Categorize the RiskDiagnoses\n",
    "pimLowRisk = [\"Asthma\",\"Bronchiolitis\",\"Croup\",\"ObstructiveSleepApnea\",\"DiabeticKetoacidosis\",'SeizureDisorder']\n",
    "pimHighRisk = [\"CerebralHemorrhage\",\"CardiomyopathyOrMyocarditis\",\"HIVPositive\",\"HypoplasticLeftHeartSyndrome\",\"NeurodegenerativeDisorder\",\"NecrotizingEnterocolitis\"]\n",
    "pimVeryHighRisk = [\"CardiacArrestInHospital\",\"CardiacArrestPreHospital\",\"SevereCombinedImmuneDeficiency\",\"LeukemiaorLymphoma\",\"BoneMarrowTransplant\",\"LiverFailure\"]\n",
    "\n",
    "# if Riskdiagnoses not known fill in unknown\n",
    "df_pice['RiskDiagnoses'] = (df_pice['RiskDiagnoses'].fillna(value='Unknown'))\n",
    "\n",
    "for i,row in df_pice.iterrows():\n",
    "    try:\n",
    "        if any(substring in df_pice.loc[i,'RiskDiagnoses'] for substring in pimVeryHighRisk) == True:\n",
    "            df_pice.loc[i,'RiskDiagnoses'] = 3\n",
    "        elif any(substring in df_pice.loc[i,'RiskDiagnoses'] for substring in pimHighRisk)==True :\n",
    "            df_pice.loc[i,'RiskDiagnoses']= 2\n",
    "        elif any(substring in df_pice.loc[i,'RiskDiagnoses'] for substring in pimLowRisk)==True:\n",
    "            df_pice.loc[i,'RiskDiagnoses'] = 1\n",
    "        else: df_pice.loc[i,'RiskDiagnoses'] = 0\n",
    "    except TypeError:\n",
    "        continue\n",
    "\n",
    "# Remove status from df_pice, it is already included in the other dataframe\n",
    "if 'Status' in list(df_pice.columns):\n",
    "    del df_pice['Status']\n",
    "print(df_pice.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   AdmissionDate    Age(days) RiskDiagnoses      Urgency  \\\n",
      "HospitalNumber                                                             \n",
      "219.0             3-3-2019 18:28  5186.769531             1  NotElective   \n",
      "377.0            21-8-2003 03:00   346.125000             0  NotElective   \n",
      "792.0            15-9-2019 16:33     4.689583             2  NotElective   \n",
      "1000.0          20-11-2003 15:00  1219.625000             0     Elective   \n",
      "1469.0          23-11-2007 13:00  4091.541748             0     Elective   \n",
      "\n",
      "                               Recovery Ventilated  AdmissionPupils  \\\n",
      "HospitalNumber                                                        \n",
      "219.0                        NoRecovery      False              0.0   \n",
      "377.0                        NoRecovery      False              0.0   \n",
      "792.0                 PostCardiacByPass       True              0.0   \n",
      "1000.0                       NoRecovery       True              0.0   \n",
      "1469.0          PostNonCardiacProcedure       True              0.0   \n",
      "\n",
      "                SystolicBP  BaseExcess  FiO2  ...  SystolicBloodPressureMin  \\\n",
      "HospitalNumber                                ...                             \n",
      "219.0                129.0       -24.0  0.21  ...                     129.0   \n",
      "377.0                113.0        -2.2  0.21  ...                     113.0   \n",
      "792.0                 50.0         NaN  0.40  ...                      50.0   \n",
      "1000.0               100.0         NaN  0.30  ...                     100.0   \n",
      "1469.0               136.0        -5.1  0.60  ...                     136.0   \n",
      "\n",
      "                TemperatureMin  TemperatureMax  BicarbonateMin  \\\n",
      "HospitalNumber                                                   \n",
      "219.0                      NaN             NaN             4.5   \n",
      "377.0                      NaN             NaN             NaN   \n",
      "792.0                35.599998       37.400002            15.2   \n",
      "1000.0                     NaN             NaN             NaN   \n",
      "1469.0                     NaN             NaN             NaN   \n",
      "\n",
      "                BicarbonateMax UreaMax WhiteBloodCountMin PRISM3Neuro  \\\n",
      "HospitalNumber                                                          \n",
      "219.0                     16.6     9.0               22.1         0.0   \n",
      "377.0                      NaN     NaN                NaN         0.0   \n",
      "792.0                     22.0     NaN                8.5         0.0   \n",
      "1000.0                     NaN     NaN                NaN         0.0   \n",
      "1469.0                     NaN     NaN                NaN         0.0   \n",
      "\n",
      "                PRISM3Score  PRISM4Mortality  \n",
      "HospitalNumber                                \n",
      "219.0                  15.0         0.017706  \n",
      "377.0                   0.0         0.039849  \n",
      "792.0                  16.0         0.300483  \n",
      "1000.0                  0.0         0.022032  \n",
      "1469.0                  0.0         0.022032  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "                Age(days)  AdmissionPupils  SystolicBP  BaseExcess      FiO2  \\\n",
      "HospitalNumber                                                                 \n",
      "219.0            1.317976              0.0    0.861111   -4.666667 -0.473684   \n",
      "377.0           -0.156776              0.0    0.416667    0.177778 -0.473684   \n",
      "792.0           -0.260798              0.0   -1.333333         NaN  0.526316   \n",
      "1000.0           0.109345              0.0    0.055556         NaN  0.000000   \n",
      "1469.0           0.984304              0.0    1.055556   -0.466667  1.578947   \n",
      "\n",
      "                    PaO2  PIM2Score   PIM2Mort  PIM3Score  PIM3Mort  ...  \\\n",
      "HospitalNumber                                                       ...   \n",
      "219.0           0.173913   0.220702   0.209928  -0.282613 -0.190393  ...   \n",
      "377.0                NaN  -0.132967  -0.086739   0.095824  0.088812  ...   \n",
      "792.0                NaN   1.907404  11.467878   1.017476  2.302942  ...   \n",
      "1000.0               NaN   0.033052   0.025609   0.308473  0.346846  ...   \n",
      "1469.0          0.069565  -0.152869  -0.097747  -0.287123 -0.192737  ...   \n",
      "\n",
      "                SystolicBloodPressureMin  TemperatureMin  TemperatureMax  \\\n",
      "HospitalNumber                                                             \n",
      "219.0                           0.861111             NaN             NaN   \n",
      "377.0                           0.416667             NaN             NaN   \n",
      "792.0                          -1.333333       -1.100002             0.0   \n",
      "1000.0                          0.055556             NaN             NaN   \n",
      "1469.0                          1.055556             NaN             NaN   \n",
      "\n",
      "                BicarbonateMin  BicarbonateMax   UreaMax  WhiteBloodCountMin  \\\n",
      "HospitalNumber                                                                 \n",
      "219.0                -3.509805       -1.756097  1.294964            1.097674   \n",
      "377.0                      NaN             NaN       NaN                 NaN   \n",
      "792.0                -1.411765       -0.439024       NaN           -0.167442   \n",
      "1000.0                     NaN             NaN       NaN                 NaN   \n",
      "1469.0                     NaN             NaN       NaN                 NaN   \n",
      "\n",
      "                PRISM3Neuro  PRISM3Score  PRISM4Mortality  \n",
      "HospitalNumber                                             \n",
      "219.0                   0.0         15.0        -0.177805  \n",
      "377.0                   0.0          0.0         0.732343  \n",
      "792.0                   0.0         16.0        11.445245  \n",
      "1000.0                  0.0          0.0         0.000000  \n",
      "1469.0                  0.0          0.0         0.000000  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:993: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1370: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input, interpolation=interpolation\n"
     ]
    }
   ],
   "source": [
    "# remove duplicate patients\n",
    "#df_pice=df_pice[~df_pice.index.duplicated(keep='last')]\n",
    "print(df_pice.head())\n",
    "# Applying robust scaling to numerical columns of PICE\n",
    "scaler=RobustScaler()\n",
    "float_columns_pice = list(df_pice.select_dtypes(include=['float64']).columns)\n",
    "df_pice_temp=df_pice[float_columns_pice]\n",
    "df_pice_scaled=pd.DataFrame(scaler.fit_transform(df_pice_temp), columns=float_columns_pice,index=df_pice_temp.index)\n",
    "print(df_pice_scaled.head())\n",
    "df_pice[float_columns_pice]=df_pice_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6743 entries, 1936 to 9996691\n",
      "Data columns (total 62 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Age_max               6743 non-null   float64\n",
      " 1   lab_bl_ur_count       6743 non-null   float64\n",
      " 2   lab_bl_ur_std         453 non-null    float64\n",
      " 3   lab_bl_ur_max         1301 non-null   float64\n",
      " 4   lab_bl_tr_count       6743 non-null   float64\n",
      " 5   lab_bl_tr_std         1094 non-null   float64\n",
      " 6   lab_bl_tr_max         2853 non-null   float64\n",
      " 7   lab_bl_na_count       6743 non-null   float64\n",
      " 8   lab_bl_na_std         3792 non-null   float64\n",
      " 9   lab_bl_na_max         5228 non-null   float64\n",
      " 10  lab_bl_mg_count       6743 non-null   float64\n",
      " 11  lab_bl_mg_std         494 non-null    float64\n",
      " 12  lab_bl_mg_max         1530 non-null   float64\n",
      " 13  lab_bl_leuco_count    6743 non-null   float64\n",
      " 14  lab_bl_leuco_std      658 non-null    float64\n",
      " 15  lab_bl_leuco_max      1699 non-null   float64\n",
      " 16  lab_bl_lactate_count  6743 non-null   float64\n",
      " 17  lab_bl_lactate_std    1770 non-null   float64\n",
      " 18  lab_bl_lactate_max    3073 non-null   float64\n",
      " 19  lab_bl_k_count        6743 non-null   float64\n",
      " 20  lab_bl_k_std          3794 non-null   float64\n",
      " 21  lab_bl_k_max          5228 non-null   float64\n",
      " 22  lab_bl_ht_count       6743 non-null   float64\n",
      " 23  lab_bl_ht_std         3999 non-null   float64\n",
      " 24  lab_bl_ht_max         5295 non-null   float64\n",
      " 25  lab_bl_hb_count       6743 non-null   float64\n",
      " 26  lab_bl_hb_std         4021 non-null   float64\n",
      " 27  lab_bl_hb_max         5303 non-null   float64\n",
      " 28  lab_bl_gluc_count     6743 non-null   float64\n",
      " 29  lab_bl_gluc_std       3853 non-null   float64\n",
      " 30  lab_bl_gluc_max       5259 non-null   float64\n",
      " 31  lab_bl_f_count        6743 non-null   float64\n",
      " 32  lab_bl_f_std          174 non-null    float64\n",
      " 33  lab_bl_f_max          413 non-null    float64\n",
      " 34  lab_bl_CRP_count      6743 non-null   float64\n",
      " 35  lab_bl_CRP_std        443 non-null    float64\n",
      " 36  lab_bl_CRP_max        1223 non-null   float64\n",
      " 37  lab_bl_cr_count       6743 non-null   float64\n",
      " 38  lab_bl_cr_std         487 non-null    float64\n",
      " 39  lab_bl_cr_max         1378 non-null   float64\n",
      " 40  lab_bl_cl_count       6743 non-null   float64\n",
      " 41  lab_bl_cl_std         233 non-null    float64\n",
      " 42  lab_bl_cl_max         692 non-null    float64\n",
      " 43  lab_bl_cc_count       6743 non-null   float64\n",
      " 44  lab_bl_cc_std         2 non-null      float64\n",
      " 45  lab_bl_cc_max         3 non-null      float64\n",
      " 46  lab_bl_catot_count    6743 non-null   float64\n",
      " 47  lab_bl_catot_std      100 non-null    float64\n",
      " 48  lab_bl_catot_max      289 non-null    float64\n",
      " 49  lab_bl_ca2_count      6743 non-null   float64\n",
      " 50  lab_bl_ca2_std        3603 non-null   float64\n",
      " 51  lab_bl_ca2_max        5078 non-null   float64\n",
      " 52  lab_bl_bil_i_count    6743 non-null   float64\n",
      " 53  lab_bl_bil_i_std      175 non-null    float64\n",
      " 54  lab_bl_bil_i_max      384 non-null    float64\n",
      " 55  lab_bl_bil_d_count    6743 non-null   float64\n",
      " 56  lab_bl_bil_d_std      113 non-null    float64\n",
      " 57  lab_bl_bil_d_max      250 non-null    float64\n",
      " 58  lab_bl_b2m_count      6743 non-null   float64\n",
      " 59  lab_bl_b2m_std        0 non-null      float64\n",
      " 60  lab_bl_b2m_max        0 non-null      float64\n",
      " 61  Label                 6743 non-null   object \n",
      "dtypes: float64(61), object(1)\n",
      "memory usage: 3.2+ MB\n",
      "None\n",
      "['AdmissionDate', 'Age(days)', 'RiskDiagnoses', 'Urgency', 'Recovery', 'Ventilated', 'AdmissionPupils', 'SystolicBP', 'BaseExcess', 'FiO2', 'PaO2', 'AdmissionSource', 'Cancer', 'CPR24HourBefore', 'CreatinineMax', 'GlucoseMax', 'HeartRateMax', 'LowRiskPrimary', 'MentalStatus', 'PaO2Min', 'PCO2Max', 'PHMin', 'PHMax', 'PlateletsMin', 'PotassiumMax', 'PTMax', 'PTTMax', 'PupilsFixed', 'SystolicBloodPressureMin', 'TemperatureMin', 'TemperatureMax', 'BicarbonateMin', 'BicarbonateMax', 'UreaMax', 'WhiteBloodCountMin']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Sorting PICE in two dataframes\n",
    "# one with only Scores and the other with only modalities\n",
    "all_pice_columns=list(df_pice.columns)\n",
    "score_mor=['PIM3Score', 'PIM3Mort', 'PIM2Mort', 'PRISM4Mortality','PIM2Score','PRISM3Neuro','PRISM3Score']\n",
    "pice_items= list((Counter(all_pice_columns)-Counter(score_mor)).elements())\n",
    "df_pice_scores=df_pice[score_mor]\n",
    "df_pice_modalities=df_pice[pice_items]\n",
    "print(df_try_full.info())\n",
    "print(pice_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10156 entries, 0 to 10155\nColumns: 104 entries, Age_max to ReHospitalisation\ndtypes: float64(75), int8(20), object(9)\nmemory usage: 6.7+ MB\nNone\n   Age_max  lab_bl_ur_count  lab_bl_ur_std  lab_bl_ur_max  lab_bl_tr_count  \\\n0      0.0                0            NaN            NaN                0   \n1      0.0                1            NaN      -0.111111                1   \n2      1.0                0            NaN            NaN                1   \n3      2.0                0            NaN            NaN                0   \n4      2.0                0            NaN            NaN                0   \n\n   lab_bl_tr_std  lab_bl_tr_max  lab_bl_na_count  lab_bl_na_std  \\\n0            NaN            NaN                1            NaN   \n1            NaN      -0.904762                4       0.125000   \n2            NaN      -1.332258                3      15.992915   \n3            NaN            NaN                6      19.170290   \n4            NaN            NaN                6      19.170290   \n\n   lab_bl_na_max  ...  TemperatureMin  TemperatureMax  BicarbonateMin  \\\n0          -1.50  ...             NaN             NaN             NaN   \n1          -0.50  ...             NaN             NaN             NaN   \n2           0.00  ...             NaN             NaN             NaN   \n3           0.25  ...             NaN             NaN             NaN   \n4           0.25  ...             NaN             NaN             NaN   \n\n   BicarbonateMax  UreaMax  WhiteBloodCountMin  PRISM3Neuro  PRISM3Score  \\\n0             NaN      NaN                 NaN          0.0          0.0   \n1             NaN      NaN                 NaN          0.0          0.0   \n2             NaN      NaN                 NaN          0.0          0.0   \n3             NaN      NaN                 NaN          0.0          3.0   \n4             NaN      NaN                 NaN          0.0          0.0   \n\n   PRISM4Mortality  ReHospitalisation  \n0        -0.787183                0.0  \n1        -0.557867                0.0  \n2         0.000000                0.0  \n3         0.124581                0.0  \n4        -0.724221                0.0  \n\n[5 rows x 104 columns]\n0    9676\n1     480\nName: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from collections import Counter \n",
    "# copy df as failsafe\n",
    "df_coms=df_try_full\n",
    "# binarize the status of a patient Alive = 0, Death = 1\n",
    "lb=LabelBinarizer()\n",
    "df_coms['Label']=lb.fit_transform(df_coms['Label'])\n",
    "\n",
    "# Selecting the correct datatype for all columns\n",
    "a=list(df_coms.columns)\n",
    "a.remove('Label')\n",
    "for column in a:\n",
    "    if 'top' in column:\n",
    "        df_coms[column]=df_coms[column].astype('object')\n",
    "    elif 'count' in column:\n",
    "        df_coms[column]=df_coms[column].astype('int8')\n",
    "    else:\n",
    "        df_coms[column]=df_coms[column].astype('float64')\n",
    "\n",
    "# Join PICE and PICURED\n",
    "df_com=df_coms.join(df_pice,how='left')\n",
    "df_com = df_com.reset_index()\n",
    "\n",
    "# Add variable for rehospitalisation\n",
    "for i,row in df_com.iterrows():\n",
    "    if  df_com.index[i] in duplicate_patients:\n",
    "        df_com.loc[i,'ReHospitalisation'] = 1\n",
    "    else:\n",
    "        df_com.loc[i,'ReHospitalisation'] = 0\n",
    "\n",
    "# Seperate data from  label\n",
    "x=df_com.drop(['index','Label'],axis=1)\n",
    "y=df_com['Label']\n",
    "\n",
    "print(x.info())\n",
    "\n",
    "print(x.head())\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caculate correlation of data with label\n",
    "c=x.corrwith(y,method='pearson')\n",
    "d=x.corrwith(y,method='spearman')\n",
    "\n",
    "# Select relevant features based on cut-off values\n",
    "relevant_features_pe = c[c>0.05]\n",
    "relevant_features_sp = d[d>0.05]\n",
    "\n",
    "# Extract correlating features from main dataframe\n",
    "x_pe=x[relevant_features_pe.index]\n",
    "x_sp=x[relevant_features_sp.index]\n",
    "\n",
    "\n",
    "# Top features from trained classifiers (linear svm, decisiontree, logistic regression)\n",
    "#top=['lab_bl_catot_mean', 'lab_bl_catot_max', 'CPR24HourBefore', 'lab_bl_f_mean', 'lab_bl_na_count', 'lab_bl_lactate_mean', 'lab_bl_catot_std', 'lab_bl_f_min', 'lab_bl_k_count', 'lab_bl_bil_d_std', 'lab_bl_gluc_mean', 'lab_bl_gluc_max', 'lab_bl_ur_mean', 'lab_bl_ht_std', 'lab_bl_bil_i_std', 'lab_bl_na_std', 'Urgency', 'lab_bl_ur_max', 'LowRiskPrimary', 'lab_bl_catot_min', 'lab_bl_ht_max', 'lab_bl_leuco_std', 'lab_bl_cl_count', 'Cancer', 'lab_bl_CRP_std', 'lab_bl_k_mean', 'lab_bl_lactate_max']\n",
    "#top=['lab_bl_na_count', 'lab_bl_catot_mean', 'lab_bl_k_count', 'lab_bl_hb_max', 'lab_bl_catot_max', 'PHMax', 'lab_bl_bil_d_std', 'lab_bl_na_std', 'PHMin', 'lab_bl_mg_std', 'lab_bl_ht_mean', 'Recovery', 'lab_bl_cl_count', 'lab_bl_mg_max', 'lab_bl_hb_mean', 'CPR24HourBefore', 'lab_bl_catot_std', 'lab_bl_k_std']\n",
    "\n",
    "# Extract top features from dataframe\n",
    "#x_top=x[top]\n",
    "#x_top = x_top.loc[:,~x_top.columns.duplicated()]\n",
    "#print(x_top.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,PolynomialFeatures,StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer,IterativeImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,ComplementNB,CategoricalNB,BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF,DotProduct,Matern,RationalQuadratic,WhiteKernel\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis,LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import NearestCentroid,NeighborhoodComponentsAnalysis,KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression,MultiTaskLasso,ElasticNetCV,BayesianRidge,LogisticRegression,RidgeClassifierCV,LassoCV,LassoLarsCV,OrthogonalMatchingPursuitCV\n",
    "from sklearn.ensemble import AdaBoostRegressor,BaggingClassifier,RandomForestClassifier,ExtraTreesClassifier,AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score,StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel,RFE,VarianceThreshold,RFECV,SelectPercentile, chi2,SelectKBest\n",
    "from sklearn.svm import SVC,SVR,LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix,average_precision_score,plot_precision_recall_curve\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,plot_confusion_matrix,f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from probatus.feature_elimination import ShapRFECV\n",
    "import lightgbm\n",
    "import xgboost\n",
    "from all_own_functions import f_importances\n",
    "import os\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "def machine_learning_function(x_train,x_test,y_train,y_test,model,wrapper=0):\n",
    "    \"\"\"\n",
    "    Function which takes train and test data and uses it to train a specified model, also the option to use wrapper based feature selection model\n",
    "    Also preforms dataimputation and onehotencoding\n",
    "    \"\"\"\n",
    "    # specify types of variables, since it changes the imputation\n",
    "    float_columns=list(x_train.select_dtypes(include=['float64']).columns)\n",
    "    int_columns=list(x_train.select_dtypes(include=['int32']).columns)\n",
    "    cat_list=list(x_train.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "    # remove label if still in x_train\n",
    "    if 'Label' in float_columns: float_colums.remove('Label')\n",
    "\n",
    "    #imputation and one hot encoding\n",
    "    float_transformer = Pipeline(steps=[('imputer',SimpleImputer(strategy='most_frequent'))])\n",
    "    int_transformer = Pipeline(steps=[('imputer',SimpleImputer(strategy='constant',fill_value=0))])\n",
    "    cat_transformer = Pipeline(steps=[('imputer',SimpleImputer(strategy='constant',fill_value='Unknown')),('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    # group all preprocessing\n",
    "    preprocess = ColumnTransformer(transformers=[('float',float_transformer,float_columns),('int',int_transformer,int_columns),('cat',cat_transformer,cat_list)],                       remainder='passthrough')\n",
    "    \n",
    "    # create machine learning pipeline, wrapper specifies the feature selection\n",
    "    if wrapper == 1:\n",
    "        clf = Pipeline(steps=[('preprocessor',preprocess),('Feature_selection',SelectFromModel(LinearSVC(max_iter=3000))),\n",
    "        ('classifier',model)])\n",
    "    elif wrapper == 2:\n",
    "        clf = Pipeline(steps=[('preprocessor',preprocess),('Feature_selection',SelectFromModel(DecisionTreeClassifier())),\n",
    "        ('classifier',model)])\n",
    "    elif wrapper == 3:\n",
    "        clf = Pipeline(steps=[('preprocessor',preprocess),('Feature_selection',SelectFromModel(LogisticRegression())),\n",
    "        ('classifier',model)])\n",
    "    else:\n",
    "        clf = Pipeline(steps=[('preprocessor',preprocess),('classifier',model)])\n",
    "\n",
    "    # fit the pipeline to the data\n",
    "    clf=clf.fit(x_train,y_train)\n",
    "    # Predict the labels\n",
    "    y_pred_clas=clf.predict(x_test)\n",
    "\n",
    "    # Predict the probabilities, function depends on used classifier\n",
    "\n",
    "    try:\n",
    "        y_pred_prob=clf.decision_function(x_test)\n",
    "    except:\n",
    "        try:\n",
    "            y_pred_prob=clf.predict_proba(x_test)\n",
    "            y_pred_prob=y_pred_prob[:,1]\n",
    "        except:\n",
    "            y_pred_prob=y_pred_clas\n",
    "\n",
    "    # failsafe to inpute NaN probabilities with 0\n",
    "    inds = np.where(np.isnan(y_pred_prob))\n",
    "    if inds:\n",
    "        y_pred_prob=np.nan_to_num(y_pred_prob, nan=0)\n",
    "    return clf, y_pred_clas,y_pred_prob, y_test,x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,brier_score_loss\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "# speciify colours for plot later on\n",
    "colours=['b-', 'g--', 'r:', 'c-.', 'm-+', 'y-*', 'k-o']\n",
    "\n",
    "\n",
    "# Stratiefied fold for cros-validation\n",
    "fold=StratifiedKFold(3)\n",
    "\n",
    "# Names and classiefiers to be used in the loop\n",
    "names = [ \"Random Forest\", \"Gaus Naive Bayes\",\n",
    "        \"Decision Tree Clas\", \"Sigmoid SVM\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1,class_weight={0:.1, 1:.9}),\n",
    "    GaussianNB(priors=[0.9 , 0.1]),\n",
    "    DecisionTreeClassifier(class_weight= {0:.1, 1:.9}),\n",
    "    SVC(kernel='sigmoid',class_weight= {0:.1, 1:.9},probability=True),\n",
    "    QuadraticDiscriminantAnalysis(priors=[0.9,0.1])\n",
    "    ]\n",
    "\n",
    "# Names and dataframes used in the loop\n",
    "data_names=['All_Data','Pearson_Cor', 'Spearman_cor',\"Wrap_Lin_SVM\",\"Wrap_Dec_Tree\",\"Wrap_Log_Reg\"]\n",
    "x_data=[x, x_pe, x_sp, x, x, x]\n",
    "\n",
    "# split data in train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=1 / 5, random_state=1)\n",
    "\n",
    "# calculate ROC and AUC outside of loop\n",
    "fpr_pim, tpr_pim, _ = roc_curve(y_test,  x_test['PIM3Score'])\n",
    "auc_pim = roc_auc_score(y_test, x_test['PIM3Score'])\n",
    "\n",
    "# check if result files do not already exist, updating pdf is not possible\n",
    "try:\n",
    "    pdf = PdfPages(os.path.join(output_folder,f\"Figures of {hour} hour results.pdf\"))\n",
    "    pdf_ROC = PdfPages(os.path.join(output_folder,f\"ROC of {hour} hour results.pdf\"))\n",
    "    pdf_cal = PdfPages(os.path.join(output_folder,f\"Cal of {hour} hour results.pdf\"))\n",
    "    pdf_hist = PdfPages(os.path.join(output_folder,f\"Hist of {hour} hour results.pdf\"))\n",
    "except PermissionError:\n",
    "    os.remove(os.path.join(output_folder,f\"Figures of {hour} hour results.pdf\"))\n",
    "    os.remove(os.path.join(output_folder,f\"ROC of {hour} hour results.pdf\"))\n",
    "    os.remove(os.path.join(output_folder,f\"Results_{hour}hours_scores.txt\"))\n",
    "    os.remove(os.path.join(output_folder,f\"Cal of {hour} hour results.pdf\"))\n",
    "    os.remove(os.path.join(output_folder,f\"Hist of {hour} hour results.pdf\"))\n",
    "    pdf = PdfPages(os.path.join(output_folder,f\"Figures of {hour} hour results.pdf\"))\n",
    "    pdf_ROC= PdfPages(os.path.join(output_folder,f\"ROC of {hour} hour results.pdf\"))\n",
    "    pdf_cal = PdfPages(os.path.join(output_folder,f\"Cal of {hour} hour results.pdf\"))\n",
    "    pdf_hist = PdfPages(os.path.join(output_folder,f\"Hist {hour}  hour results.pdf\"))\n",
    "\n",
    "# loop over different data and feature selection techniques\n",
    "for data_name, xd in zip(data_names, x_data):\n",
    "    # transform columns based on dataframe used\n",
    "    columns = xd.columns.tolist()\n",
    "    x_train_d = x_train[columns]\n",
    "    x_test_d = x_test[columns]\n",
    "    \n",
    "    # Add variable for wrapper based feature selection\n",
    "    if 'Wrap' in data_name:\n",
    "        wrapper += 1\n",
    "    else:\n",
    "        wrapper=0\n",
    "    \n",
    "    # create variables for temp storage lateron\n",
    "    temp_fpr=dict()\n",
    "    temp_tpr=dict()\n",
    "    temp_auc=dict()\n",
    "    temp_probtrue={}\n",
    "    temp_probpred={}\n",
    "    temp_score={}\n",
    "\n",
    "    # loop over different classifiers\n",
    "    for name, clf_s in zip(names, classifiers):\n",
    "\n",
    "        clf,y_pred_clas,y_pred_prob,y_test,x_test_d = machine_learning_function(x_train_d,x_test_d,y_train,y_test,clf_s,wrapper)\n",
    "\n",
    "        # calculate scoring metrics\n",
    "        report=classification_report(y_test,y_pred_clas,target_names=['Alive','Death'])\n",
    "        score=clf.score(x_test_d,y_test)\n",
    "        average_precision = average_precision_score(y_test, y_pred_prob)\n",
    "        f1_s=f1_score(y_test, y_pred_clas)\n",
    "\n",
    "        # write scoring metrics to file\n",
    "        with open(os.path.join(output_folder,f\"Results_{hour}hours_scores.txt\"),'a') as file:\n",
    "            file.write(f\"{data_name} with {name} Results for {hour} hours \\n\\n\")\n",
    "            file.write(f\"Classification report \\n {report} \\n\")\n",
    "            file.write(f\"Hold_out_scores {score} \\n\")\n",
    "            file.write(f\"Average precision score {average_precision} \\n\")\n",
    "            file.write(f\"F1 score {f1_s} \\n\\n\\n\")\n",
    "        \n",
    "        # plot confusion matrix\n",
    "        plot_confusion_matrix(clf,x_test_d,y_test)\n",
    "        plt.title(f\"{data_name} with {name} classifier, Results from {hour} hour data\")\n",
    "        fig=plt.gcf()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # plot ROC with AUC\n",
    "        fpr, tpr, _ = roc_curve(y_test,  y_pred_prob)\n",
    "        auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        plt.plot(fpr,tpr,label=f\"{name}, auc={auc}\")\n",
    "        plt.plot(fpr_pim,tpr_pim,label=f\"PIM3Score, auc={auc_pim}\")\n",
    "        plt.title(f\"{data_name} with {name} classifier, Results from {hour} hour data\")\n",
    "        plt.legend(loc=4)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        fig=plt.gcf()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # temporarly store ROC and AUC per classifier\n",
    "        temp_fpr.update({f'{name}': fpr})\n",
    "        temp_tpr.update({f'{name}': tpr})\n",
    "        temp_auc.update({f'{name}': auc})\n",
    "\n",
    "         # plot callibration plot with brier_loss score\n",
    "        \n",
    "        prob_true, prob_pred = calibration_curve(y_test,  y_pred_prob,normalize=True)\n",
    "        plt.plot(prob_pred,prob_true,label=f\"{name} \")\n",
    "        plt.title(f\"{data_name} with {name} classifier, Results from {hour} hour data\")\n",
    "        plt.legend(loc=4)\n",
    "        plt.ylabel('Fraction of Positives')\n",
    "        fig=plt.gcf()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # temporarly store ROC and AUC per classifier\n",
    "        temp_probtrue.update({f'{name}': prob_true})\n",
    "        temp_probpred.update({f'{name}': prob_pred})\n",
    "        #temp_score.update({f'{name}':clf_score})\n",
    "        \n",
    "    #PLot every roc from the used classifier per feature selection method \n",
    "    a=0\n",
    "    for k,v in temp_fpr.items():\n",
    "        plt.plot(v,temp_tpr.get(k),colours[a],label=f\"{k}, auc={temp_auc.get(k)}\",linewidth=1.5,markersize=1)\n",
    "        a= a+1\n",
    "    plt.plot(fpr_pim,tpr_pim,'b->',label=f\"PIM3Score, auc={auc_pim}\",linewidth=1.5,markersize=1)\n",
    "    plt.legend(loc=4,fontsize='xx-small')\n",
    "    plt.title(f'{data_name} ROC from {hour} hour data')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,1])\n",
    "    axes.set_ylim([0,1])\n",
    "    fig=plt.gcf()\n",
    "    pdf_ROC.savefig(fig)\n",
    "    plt.close(fig)\n",
    "    count=0\n",
    "\n",
    "    #PLot calibration from the used classifier per feature selection method\n",
    "    for k,v in temp_probtrue.items():\n",
    "        plt.plot(temp_probpred.get(k),v,colours[count],label=f\"{k}\",linewidth=1.5,markersize=1)\n",
    "        count += 1\n",
    "    plt.legend(loc=4,fontsize='xx-small')\n",
    "    plt.title(f'{data_name} Calibration Curve from {hour} hour data')\n",
    "    plt.xlabel('Fraction of positives')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,1])\n",
    "    axes.set_ylim([0,1])\n",
    "    fig=plt.gcf()\n",
    "    pdf_cal.savefig(fig)\n",
    "    plt.close(fig)\n",
    "    count=0\n",
    "\n",
    "    # plot histogram from the used classifier per feature selection method\n",
    "    for k,v in temp_probtrue.items():\n",
    "        plt.hist(temp_probpred.get(k),range=(0,1),label=f\"{k}\",histtype='step',lw=2)\n",
    "        count += 1\n",
    "    plt.legend(loc=4,fontsize='xx-small')\n",
    "    plt.title(f'{data_name} Calibration Curve from {hour} hour data')\n",
    "    plt.xlabel('Fraction of positives')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,1])\n",
    "    axes.set_ylim([0,1])\n",
    "    fig=plt.gcf()\n",
    "    pdf_hist.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "    del temp_fpr,temp_tpr,temp_auc\n",
    "pdf.close()\n",
    "pdf_ROC.close()\n",
    "pdf_cal.close()\n",
    "pdf_hist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "# Same functions as before except now specified for Regression algorithms\n",
    "\n",
    "names = [\"Logistic Regression\"\n",
    "        ]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    ]\n",
    "\n",
    "try:\n",
    "    pdf_ROC= PdfPages(os.path.join(output_folder,f\"ROC of {hour} hour results_regression.pdf\"))\n",
    "except PermissionError:\n",
    "    os.remove(os.path.join(output_folder,f\"ROC of {hour} hour results_regression.pdf\"))\n",
    "    pdf_ROC= PdfPages(os.path.join(output_folder,f\"ROC of {hour} hour results_regression.pdf\"))\n",
    "\n",
    "for data_name, xd in zip(names, x_data):\n",
    "    columns = xd.columns.tolist()\n",
    "    x_train_d = x_train[columns]\n",
    "    x_test_d = x_test[columns]\n",
    "\n",
    "    if 'Wrap' in data_name:\n",
    "        wrapper += 1\n",
    "    else:\n",
    "        wrapper=0\n",
    "\n",
    "    temp_fpr=dict()\n",
    "    temp_tpr=dict()\n",
    "    temp_auc=dict()\n",
    "\n",
    "    for name, clf_s in zip(names, classifiers):\n",
    "\n",
    "        clf,y_pred_clas,y_pred_prob,y_test,x_test_d = machine_learning_function(x_train_d,x_test_d,y_train,y_test,clf_s,wrapper)\n",
    "\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test,  y_pred_prob)\n",
    "        auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "\n",
    "        temp_fpr.update({f'{name}': fpr})\n",
    "        temp_tpr.update({f'{name}': tpr})\n",
    "        temp_auc.update({f'{name}': auc})\n",
    "    a=0\n",
    "    for k,v in temp_fpr.items():\n",
    "        plt.plot(v,temp_tpr.get(k),colours[a],label=f\"{k}, auc={temp_auc.get(k)}\",linewidth=1.5,markersize=1)\n",
    "        a= a+1\n",
    "    plt.plot(fpr_pim,tpr_pim,'b->',label=f\"PIM3Score, auc={auc_pim}\",linewidth=1.5,markersize=1)\n",
    "    plt.legend(loc=4,fontsize='xx-small')\n",
    "    plt.title(f'{data_name} ROC of {hour} hour data')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,1])\n",
    "    axes.set_ylim([0,1])\n",
    "    fig=plt.gcf()\n",
    "    pdf_ROC.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    del temp_fpr,temp_tpr,temp_auc\n",
    "pdf_ROC.close()\n",
    "\n",
    "\n",
    "        \n",
    "#score metrics for regression classifiers\n",
    "\"\"\"\"\"\n",
    "print(metrics.explained_variance_score(y_test,y_pred))\n",
    "print(metrics.max_error(y_test,y_pred))\n",
    "print(metrics.mean_absolute_error(y_test,y_pred))\n",
    "print(metrics.mean_squared_error(y_test,y_pred))\n",
    "print(metrics.mean_squared_error(y_test,y_pred))\n",
    "print(metrics.median_absolute_error(y_test,y_pred))\n",
    "print(metrics.r2_score(y_test,y_pred))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original ROC area: {:0.3f}\".format(roc_auc_score(y_true, y_pred)))\n",
    "\n",
    "n_bootstraps = 1000\n",
    "rng_seed = 42  # control reproducibility\n",
    "bootstrapped_scores = []\n",
    "\n",
    "rng = np.random.RandomState(rng_seed)\n",
    "for i in range(n_bootstraps):\n",
    "    # bootstrap by sampling with replacement on the prediction indices\n",
    "    indices = rng.randint(0, len(y_pred), len(y_pred))\n",
    "    if len(np.unique(y_true[indices])) < 2:\n",
    "        # We need at least one positive and one negative sample for ROC AUC\n",
    "        # to be defined: reject the sample\n",
    "        continue\n",
    "\n",
    "    score = roc_auc_score(y_true[indices], y_pred[indices])\n",
    "    bootstrapped_scores.append(score)\n",
    "    print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\n",
    "\n",
    "sorted_scores = np.array(bootstrapped_scores)\n",
    "sorted_scores.sort()\n",
    "\n",
    "# Computing the lower and upper bound of the 90% confidence interval\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "# a 95% confidence interval instead.\n",
    "confidence_lower = sorted_scores[int(0.05 * len(sorted_scores))]\n",
    "confidence_upper = sorted_scores[int(0.95 * len(sorted_scores))]\n",
    "print(\"Confidence interval for the score: [{:0.3f} - {:0.3}]\".format(\n",
    "    confidence_lower, confidence_upper))\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from math import sqrt\n",
    "\n",
    "def roc_auc_ci(y_true, y_score, positive=1):\n",
    "    AUC = roc_auc_score(y_true, y_score)\n",
    "    N1 = sum(y_true == positive)\n",
    "    N2 = sum(y_true != positive)\n",
    "    Q1 = AUC / (2 - AUC)\n",
    "    Q2 = 2*AUC**2 / (1 + AUC)\n",
    "    SE_AUC = sqrt((AUC*(1 - AUC) + (N1 - 1)*(Q1 - AUC**2) + (N2 - 1)*(Q2 - AUC**2)) / (N1*N2))\n",
    "    lower = AUC - 1.96*SE_AUC\n",
    "    upper = AUC + 1.96*SE_AUC\n",
    "    if lower < 0:\n",
    "        lower = 0\n",
    "    if upper > 1:\n",
    "        upper = 1\n",
    "    return (lower, upper)\n",
    "a=roc_auc_ci(y_true,y_pred)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is used to calculate the absolute feature importances of a classifier, with the current code, this snippet does not currently work\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "for k,v in models.items():\n",
    "    clf,y_pred,y_test,float_colums,cat_list = machine_learning_function(x_sp,y,v,k)\n",
    "    #onehot_columns = list(clf.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names(input_features=cat_list))\n",
    "    #float_colums.extend(onehot_columns)\n",
    "    try:\n",
    "        coefs = clf.named_steps[\"classifier\"].coef_.flatten()\n",
    "    except:\n",
    "        coefs=clf.named_steps[\"classifier\"].feature_importances_\n",
    "    import pandas as pd\n",
    "    # Zip coefficients and names together and make a DataFrame\n",
    "    zipped = zip(float_colums, coefs)\n",
    "    df = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "    # Sort the features by the absolute value of their coefficient\n",
    "    df[\"abs_value\"] = df[\"value\"].apply(lambda x: abs(x))\n",
    "    df[\"colors\"] = df[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "    df = df.sort_values(\"abs_value\", ascending=False)\n",
    "\n",
    "\n",
    "    import seaborn as sns\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 4))\n",
    "    sns.barplot(x=\"feature\",\n",
    "                y=\"value\",\n",
    "                data=df.head(30),\n",
    "                palette=df.head(30)[\"colors\"])\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=12)\n",
    "    ax.set_title(\"Top 20 Features\", fontsize=12)\n",
    "    ax.set_ylabel(\"Coef\", fontsize=12)\n",
    "    ax.set_xlabel(\"Feature Name\", fontsize=12)\n",
    "    print(df[\"feature\"].head(20).tolist())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn import cluster as clus\n",
    "from sklearn import metrics\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "float_colums=list(x.select_dtypes(include=['float64']).columns)\n",
    "int_columns=list(x.select_dtypes(include=['int8']).columns)\n",
    "cat_list=list((Counter(list(x.columns))-Counter(float_colums)-Counter(int_columns)).elements())\n",
    "float_transformer = Pipeline(steps=[('imputer',SimpleImputer(strategy='most_frequent'))])\n",
    "int_transformer = Pipeline(steps=[('imputer',SimpleImputer(strategy='constant',fill_value=0))])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[('imputer',SimpleImputer(strategy='constant',fill_value='Unknown')),('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[('float',float_transformer,float_colums),('int',int_transformer,int_columns),('cat',cat_transformer,cat_list)],                 remainder='passthrough')\n",
    "x_fit=preprocess.fit_transform(x)\n",
    "onehot_columns = list(preprocess.named_transformers_['cat'].named_steps['onehot'].get_feature_names(input_features=cat_list))\n",
    "int_columns.extend(float_columns)\n",
    "int_columns.extend(onehot_columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labels_true=y\n",
    "af = clus.AffinityPropagation(max_iter=500,preference=-1).fit(x_fit)\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "labels = af.labels_\n",
    "\n",
    "n_clusters_ = len(cluster_centers_indices)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\"\n",
    "      % metrics.adjusted_rand_score(labels_true, labels))\n",
    "print(\"Adjusted Mutual Information: %0.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(x_fit, labels, metric='sqeuclidean'))\n",
    "\n",
    "# #############################################################################\n",
    "# Plot result\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "\n",
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters_), colors):\n",
    "    class_members = labels == k\n",
    "    cluster_center = x_fit[cluster_centers_indices[k]]\n",
    "    plt.plot(x_fit[class_members,0],x_fit[class_members, 1], col + '.')\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "    for xs in x_fit[class_members]:\n",
    "        plt.plot([cluster_center[0], xs[0]], [cluster_center[1], xs[1]], col)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}