{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3b7e431a861a72513f361682db481bb043ab213b57189a56d42fe6b32fa57c58"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\nC:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.impute as skin\n",
    "from sqlalchemy import create_engine\n",
    "import locale\n",
    "import os\n",
    "\n",
    "output_folder=r\"C:\\Users\\berend\\Documents\\Python_Scripts\\vrije_stage\\Results_PIM\"\n",
    "hour=72\n",
    "locale.setlocale(locale.LC_ALL,'fr_FR')\n",
    "\n",
    "from all_own_functions import cnfl,value_filtering\n",
    "from All_standard_variables import conv_dict, dtype_dict,all_cols\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 9688 entries, 219.0 to 526480713.0\n",
      "Data columns (total 33 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age(days)                 9688 non-null   float64\n",
      " 1   AdmissionPupils           9360 non-null   float64\n",
      " 2   SystolicBP                8213 non-null   float64\n",
      " 3   BaseExcess                4811 non-null   float64\n",
      " 4   FiO2                      5087 non-null   float64\n",
      " 5   PaO2                      4296 non-null   float64\n",
      " 6   PIM2Score                 9688 non-null   float64\n",
      " 7   PIM2Mort                  9688 non-null   float64\n",
      " 8   PIM3Score                 9688 non-null   float64\n",
      " 9   PIM3Mort                  9688 non-null   float64\n",
      " 10  CreatinineMax             304 non-null    float64\n",
      " 11  GlucoseMax                959 non-null    float64\n",
      " 12  HeartRateMax              1157 non-null   float64\n",
      " 13  MentalStatus              0 non-null      float64\n",
      " 14  PaO2Min                   4296 non-null   float64\n",
      " 15  PCO2Max                   963 non-null    float64\n",
      " 16  PHMin                     526 non-null    float64\n",
      " 17  PHMax                     526 non-null    float64\n",
      " 18  PlateletsMin              417 non-null    float64\n",
      " 19  PotassiumMax              944 non-null    float64\n",
      " 20  PTMax                     111 non-null    float64\n",
      " 21  PTTMax                    110 non-null    float64\n",
      " 22  PupilsFixed               9360 non-null   float64\n",
      " 23  SystolicBloodPressureMin  8213 non-null   float64\n",
      " 24  TemperatureMin            830 non-null    float64\n",
      " 25  TemperatureMax            827 non-null    float64\n",
      " 26  BicarbonateMin            961 non-null    float64\n",
      " 27  BicarbonateMax            961 non-null    float64\n",
      " 28  UreaMax                   269 non-null    float64\n",
      " 29  WhiteBloodCountMin        237 non-null    float64\n",
      " 30  PRISM3Neuro               9688 non-null   float64\n",
      " 31  PRISM3Score               9688 non-null   float64\n",
      " 32  PRISM4Mortality           9688 non-null   float64\n",
      "dtypes: float64(33)\n",
      "memory usage: 2.5 MB\n",
      "None\n",
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:993: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "C:\\Users\\berend\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1370: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input, interpolation=interpolation\n"
     ]
    }
   ],
   "source": [
    "conv_pice={'BaseExcess':cnfl,'FiO2':cnfl,'PaO2':cnfl,'PIM2Score':cnfl,'PIM2Mort':cnfl,'PIM3Score':cnfl,\n",
    "'PIM3Mort':cnfl,'GlucoseMax':cnfl,'PaO2Min':cnfl,'PCO2Max':cnfl,'PHMax':cnfl,'PHMin':cnfl,'PotassiumMax':cnfl,'PTMax':cnfl,'TemperatureMax':cnfl,'TemperatureMin':cnfl,\n",
    "'BicarbonateMin':cnfl,'BicarbonateMax':cnfl,'UreaMax':cnfl,'WhiteBloodCountMin':cnfl,'PRISM4Mortality':cnfl,'Age(days)':cnfl}\n",
    "PIM3_cols=['HospitalNumber','AdmissionDate','AdmissionPupils','Urgency','Ventilated','BaseExcess','SystolicBP', 'FiO2','PaO2','Recovery','RiskDiagnoses','Status']\n",
    "df_pice=pd.read_csv('scores.csv',converters=conv_pice,header=0,delimiter=';')\n",
    "df_pice.drop(df_pice.tail(2).index,inplace=True)\n",
    "df_pice.dropna(axis=0,how='all',inplace=True)\n",
    "del df_pice['AdmissionDate']\n",
    "index_names = df_pice[df_pice['HospitalNumber'] == 'RPH'].index\n",
    "df_pice.drop(index_names, inplace=True)\n",
    "a=df_pice[df_pice['HospitalNumber'].duplicated(keep=False)]\n",
    "a=a[a['HospitalNumber'].duplicated(keep='first')]\n",
    "duplicate_patients=a['HospitalNumber'].tolist()\n",
    "df_pice=df_pice.set_index('HospitalNumber')\n",
    "df_pice=df_pice.sort_index()\n",
    "pimLowRisk = [\"Asthma\",\"Bronchiolitis\",\"Croup\",\"ObstructiveSleepApnea\",\"DiabeticKetoacidosis\",'SeizureDisorder']\n",
    "pimHighRisk = [\"CerebralHemorrhage\",\"CardiomyopathyOrMyocarditis\",\"HIVPositive\",\"HypoplasticLeftHeartSyndrome\",\"NeurodegenerativeDisorder\",\"NecrotizingEnterocolitis\"]\n",
    "pimVeryHighRisk = [\"CardiacArrestInHospital\",\"CardiacArrestPreHospital\",\"SevereCombinedImmuneDeficiency\",\"LeukemiaorLymphoma\",\"BoneMarrowTransplant\",\"LiverFailure\"]\n",
    "\n",
    "df_pice['RiskDiagnoses'] = (df_pice['RiskDiagnoses'].fillna(value='Unknown'))\n",
    "\n",
    "for i,row in df_pice.iterrows():\n",
    "    try:\n",
    "        if any(substring in df_pice.loc[i,'RiskDiagnoses'] for substring in pimVeryHighRisk) == True:\n",
    "            df_pice.loc[i,'RiskDiagnoses'] = 3\n",
    "        elif any(substring in df_pice.loc[i,'RiskDiagnoses'] for substring in pimHighRisk)==True :\n",
    "            df_pice.loc[i,'RiskDiagnoses']= 2\n",
    "        elif any(substring in df_pice.loc[i,'RiskDiagnoses'] for substring in pimLowRisk)==True:\n",
    "            df_pice.loc[i,'RiskDiagnoses'] = 1\n",
    "        else: df_pice.loc[i,'RiskDiagnoses'] = 0\n",
    "    except TypeError:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "df_pice=df_pice[~df_pice.index.duplicated(keep='last')]\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler=RobustScaler()\n",
    "float_columns_pice = list(df_pice.select_dtypes(include=['float64']).columns)\n",
    "\n",
    "df_pice_temp=df_pice[float_columns_pice]\n",
    "df_pice_scaled=pd.DataFrame(scaler.fit_transform(df_pice_temp), columns=float_columns_pice,index=df_pice_temp.index)\n",
    "print(df_pice_scaled.info())\n",
    "df_pice[float_columns_pice]=df_pice_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 9688 entries, 219.0 to 526480713.0\n",
      "Data columns (total 41 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age(days)                 9688 non-null   float64\n",
      " 1   RiskDiagnoses             9688 non-null   object \n",
      " 2   Urgency                   9688 non-null   object \n",
      " 3   Recovery                  9688 non-null   object \n",
      " 4   Ventilated                9688 non-null   object \n",
      " 5   AdmissionPupils           9360 non-null   float64\n",
      " 6   SystolicBP                8213 non-null   float64\n",
      " 7   BaseExcess                4811 non-null   float64\n",
      " 8   FiO2                      5087 non-null   float64\n",
      " 9   PaO2                      4296 non-null   float64\n",
      " 10  PIM2Score                 9688 non-null   float64\n",
      " 11  PIM2Mort                  9688 non-null   float64\n",
      " 12  PIM3Score                 9688 non-null   float64\n",
      " 13  PIM3Mort                  9688 non-null   float64\n",
      " 14  AdmissionSource           9688 non-null   object \n",
      " 15  Cancer                    9688 non-null   object \n",
      " 16  CPR24HourBefore           9688 non-null   object \n",
      " 17  CreatinineMax             304 non-null    float64\n",
      " 18  GlucoseMax                959 non-null    float64\n",
      " 19  HeartRateMax              1157 non-null   float64\n",
      " 20  LowRiskPrimary            9688 non-null   object \n",
      " 21  MentalStatus              0 non-null      float64\n",
      " 22  PaO2Min                   4296 non-null   float64\n",
      " 23  PCO2Max                   963 non-null    float64\n",
      " 24  PHMin                     526 non-null    float64\n",
      " 25  PHMax                     526 non-null    float64\n",
      " 26  PlateletsMin              417 non-null    float64\n",
      " 27  PotassiumMax              944 non-null    float64\n",
      " 28  PTMax                     111 non-null    float64\n",
      " 29  PTTMax                    110 non-null    float64\n",
      " 30  PupilsFixed               9360 non-null   float64\n",
      " 31  SystolicBloodPressureMin  8213 non-null   float64\n",
      " 32  TemperatureMin            830 non-null    float64\n",
      " 33  TemperatureMax            827 non-null    float64\n",
      " 34  BicarbonateMin            961 non-null    float64\n",
      " 35  BicarbonateMax            961 non-null    float64\n",
      " 36  UreaMax                   269 non-null    float64\n",
      " 37  WhiteBloodCountMin        237 non-null    float64\n",
      " 38  PRISM3Neuro               9688 non-null   float64\n",
      " 39  PRISM3Score               9688 non-null   float64\n",
      " 40  PRISM4Mortality           9688 non-null   float64\n",
      "dtypes: float64(33), object(8)\n",
      "memory usage: 3.1+ MB\n",
      "None\n",
      "                Age(days) RiskDiagnoses      Urgency                 Recovery  \\\n",
      "HospitalNumber                                                                  \n",
      "219.0            1.178384             1  NotElective               NoRecovery   \n",
      "377.0           -0.181476             0  NotElective               NoRecovery   \n",
      "792.0           -0.277394             2  NotElective        PostCardiacByPass   \n",
      "1000.0           0.063912             0     Elective               NoRecovery   \n",
      "1469.0           0.870707             0     Elective  PostNonCardiacProcedure   \n",
      "\n",
      "               Ventilated  AdmissionPupils  SystolicBP  BaseExcess      FiO2  \\\n",
      "HospitalNumber                                                                 \n",
      "219.0               False              0.0    0.828571   -4.565217 -0.473684   \n",
      "377.0               False              0.0    0.371429    0.173913 -0.473684   \n",
      "792.0                True              0.0   -1.428571         NaN  0.526316   \n",
      "1000.0               True              0.0    0.000000         NaN  0.000000   \n",
      "1469.0               True              0.0    1.028571   -0.456522  1.578947   \n",
      "\n",
      "                    PaO2  ...  SystolicBloodPressureMin  TemperatureMin  \\\n",
      "HospitalNumber            ...                                             \n",
      "219.0           0.104348  ...                  0.828571             NaN   \n",
      "377.0                NaN  ...                  0.371429             NaN   \n",
      "792.0                NaN  ...                 -1.428571       -1.100002   \n",
      "1000.0               NaN  ...                  0.000000             NaN   \n",
      "1469.0          0.000000  ...                  1.028571             NaN   \n",
      "\n",
      "                TemperatureMax  BicarbonateMin BicarbonateMax   UreaMax  \\\n",
      "HospitalNumber                                                            \n",
      "219.0                      NaN       -3.490196      -1.714286  1.323529   \n",
      "377.0                      NaN             NaN            NaN       NaN   \n",
      "792.0                      0.0       -1.392157      -0.428571       NaN   \n",
      "1000.0                     NaN             NaN            NaN       NaN   \n",
      "1469.0                     NaN             NaN            NaN       NaN   \n",
      "\n",
      "               WhiteBloodCountMin  PRISM3Neuro  PRISM3Score  PRISM4Mortality  \n",
      "HospitalNumber                                                                \n",
      "219.0                    0.956140          0.0         15.0        -0.177805  \n",
      "377.0                         NaN          0.0          0.0         0.732343  \n",
      "792.0                   -0.236842          0.0         16.0        11.445245  \n",
      "1000.0                        NaN          0.0          0.0         0.000000  \n",
      "1469.0                        NaN          0.0          0.0         0.000000  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "0    9360\n",
      "1     328\n",
      "Name: Status, dtype: int64\n",
      "AdmissionPupils       0.284714\n",
      "FiO2                  0.212895\n",
      "PIM2Score             0.294242\n",
      "PIM2Mort              0.411308\n",
      "PIM3Score             0.356581\n",
      "PIM3Mort              0.443829\n",
      "GlucoseMax            0.087730\n",
      "HeartRateMax          0.091225\n",
      "PCO2Max               0.071915\n",
      "PotassiumMax          0.079180\n",
      "PTMax                 0.145843\n",
      "PTTMax                0.289488\n",
      "PupilsFixed           0.284714\n",
      "WhiteBloodCountMin    0.093458\n",
      "PRISM3Neuro           0.279410\n",
      "PRISM3Score           0.110737\n",
      "PRISM4Mortality       0.095608\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelBinarizer,LabelEncoder\n",
    "from collections import Counter \n",
    "lb=LabelEncoder()\n",
    "df_pice['Status']=lb.fit_transform(df_pice['Status'])\n",
    "df_com=df_pice\n",
    "a=list(df_pice.columns)\n",
    "data_classes=['Death','Alive']\n",
    "d = dict(zip(data_classes, range(0,1)))\n",
    "df_pice['Status'].map(d,na_action='ignore')\n",
    "\n",
    "x=df_com.drop(['Status'],axis=1)\n",
    "y=df_com['Status']\n",
    "x.replace(to_replace='NULL', value=np.nan,inplace=True)\n",
    "print(x.info())\n",
    "\n",
    "print(x.head())\n",
    "print(y.value_counts())\n",
    "\n",
    "\n",
    "c=x.corrwith(y,method='pearson')\n",
    "d=x.corrwith(y,method='spearman')\n",
    "relevant_features_pe = c[c>0.05]\n",
    "relevant_features_sp = d[d>0.05]\n",
    "print(relevant_features_pe)\n",
    "x_pe=x[relevant_features_pe.index]\n",
    "x_sp=x[relevant_features_sp.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.22509779036863556\n"
     ]
    }
   ],
   "source": [
    "c=x['PIM3Score'].corr(x['PRISM3Score'],method='pearson')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC,SVR,LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix,average_precision_score,f1_score,roc_curve,roc_auc_score,plot_confusion_matrix\n",
    "from sklearn.calibration import calibration_curve\n",
    "import sklearn.metrics as metrics\n",
    "from all_own_functions import f_importances\n",
    "import os\n",
    "\n",
    "\n",
    "def machine_learning_function(x_train,x_test,y_train,y_test,model,wrapper=0):\n",
    "    float_columns=list(x_train.select_dtypes(include=['float64']).columns)\n",
    "    int_columns=list(x_train.select_dtypes(include=['int32']).columns)\n",
    "    cat_list=list(x_train.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "    if 'Label' in float_columns: float_columns.remove('Label')\n",
    "\n",
    "    float_transformer = Pipeline(steps=[('imputer',SimpleImputer(strategy='most_frequent'))])\n",
    "    int_transformer = Pipeline(steps=[('imputer',SimpleImputer(strategy='constant',fill_value=0))])\n",
    "    cat_transformer = Pipeline(steps=[('imputer',SimpleImputer(strategy='constant',fill_value='Unknown')),('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocess = ColumnTransformer(transformers=[('float',float_transformer,float_columns),('int',int_transformer,int_columns),('cat',cat_transformer,cat_list)],                       remainder='passthrough')\n",
    "\n",
    "    if wrapper == 1:\n",
    "        clf = Pipeline(steps=[('preprocessor',preprocess),('Feature_selection',SelectFromModel(LinearSVC(max_iter=5000))),('classifier',(model))])\n",
    "    elif wrapper == 2:\n",
    "        clf = Pipeline(steps=[('preprocessor',preprocess),('Feature_selection',SelectFromModel(DecisionTreeClassifier())),('classifier',(model))])\n",
    "    elif wrapper == 3:\n",
    "        clf = Pipeline(steps=[('preprocessor',preprocess),('Feature_selection',SelectFromModel(LogisticRegression())),('classifier',(model))])\n",
    "    else:\n",
    "        clf = Pipeline(steps=[('preprocessor',preprocess),('classifier',model)])\n",
    "\n",
    "    clf=clf.fit(x_train,y_train)\n",
    "    y_pred_clas=clf.predict(x_test)\n",
    "    # Predict the probabilities, function depends on used classifier\n",
    "\n",
    "    try:\n",
    "        y_pred_prob=clf.predict_proba(x_test)\n",
    "        y_pred_prob=y_pred_prob[:,1]\n",
    "    except:\n",
    "        try:\n",
    "            y_pred_prob=clf.decision_function(x_test)\n",
    "        except:\n",
    "            y_pred_prob=y_pred_clas\n",
    "    \n",
    "    # failsafe to inpute NaN probabilities with 0\n",
    "    inds = np.where(np.isnan(y_pred_prob))\n",
    "    if inds:\n",
    "        y_pred_prob=np.nan_to_num(y_pred_prob, nan=0)\n",
    "    return clf, y_pred_clas,y_pred_prob, y_test,x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from math import sqrt\n",
    "\n",
    "def roc_auc_ci(y_true, y_score, positive=1):\n",
    "    AUC = roc_auc_score(y_true, y_score)\n",
    "    N1 = sum(y_true == positive)\n",
    "    N2 = sum(y_true != positive)\n",
    "    Q1 = AUC / (2 - AUC)\n",
    "    Q2 = 2*AUC**2 / (1 + AUC)\n",
    "    SE_AUC = sqrt((AUC*(1 - AUC) + (N1 - 1)*(Q1 - AUC**2) + (N2 - 1)*(Q2 - AUC**2)) / (N1*N2))\n",
    "    lower = AUC - 1.96*SE_AUC\n",
    "    upper = AUC + 1.96*SE_AUC\n",
    "    if lower < 0:\n",
    "        lower = 0\n",
    "    if upper > 1:\n",
    "        upper = 1\n",
    "    return (lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All_data with Random Forest classifier, results from 72 hour data\n",
      "Original ROC area: 0.900\n",
      "Original ROC area, PIM3: 0.899\n",
      "Confidence interval for the score: [0.867 - 0.93]\n",
      "(0.8526212507023798, 0.9482153576101127)\n",
      "All_data with Sigmoid SVM classifier, results from 72 hour data\n",
      "Original ROC area: 0.687\n",
      "Original ROC area, PIM3: 0.899\n",
      "Confidence interval for the score: [0.638 - 0.738]\n",
      "(0.6183564310989509, 0.7565989100943327)\n",
      "C:\\Users\\berend\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "All_data with Logistic Regression classifier, results from 72 hour data\n",
      "Original ROC area: 0.915\n",
      "Original ROC area, PIM3: 0.899\n",
      "Confidence interval for the score: [0.889 - 0.941]\n",
      "(0.8708310147023177, 0.9600014254548814)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,brier_score_loss\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "# speciify colours for plot later on\n",
    "colours=['k-', 'g--', 'r:', 'c-.', 'm-+', 'y-*', 'k-o']\n",
    "\n",
    "# Stratiefied fold for cros-validation\n",
    "fold=StratifiedKFold(3)\n",
    "\n",
    "# Names and classiefiers to be used in the loop\n",
    "names = [ \"Random Forest\", \"Sigmoid SVM\"]\n",
    "\n",
    "classifiers = [\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1,class_weight={0:0.1,1:0.9}),\n",
    "    SVC(kernel='sigmoid',probability=True,class_weight={0:0.1,1:0.9}),\n",
    "    ]\n",
    "\n",
    "# Names and dataframes used in the loop\n",
    "data_names=[\"All_data\"]#,'Pearson_Cor',\"Wrap_Lin_SVM\",\"Wrap_Dec_Tree\"]\n",
    "x_data=[x['PIM3Score']]#,x_pe, x, x]\n",
    "auc_pim=0\n",
    "# split data in train and test data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=1 / 5,random_state=1)\n",
    "\n",
    "# calculate ROC and AUC outside of loop\n",
    "fpr_pim, tpr_pim, _ = roc_curve(y_test,  x_test['PIM3Score'])\n",
    "auc_pim = roc_auc_score(y_test, x_test['PIM3Score'])\n",
    "\n",
    "# check if result files do not already exist, updating pdf is not possible\n",
    "try:\n",
    "    pdf = PdfPages(os.path.join(output_folder,f\"Figures of {hour} hour results.pdf\"))\n",
    "    pdf_ROC = PdfPages(os.path.join(output_folder,f\"ROC of {hour} hour results.pdf\"))\n",
    "    pdf_cal = PdfPages(os.path.join(output_folder,f\"Cal of {hour} hour results.pdf\"))\n",
    "    pdf_hist = PdfPages(os.path.join(output_folder,f\"Hist of {hour} hour results.pdf\"))\n",
    "except PermissionError:\n",
    "    os.remove(os.path.join(output_folder,f\"Figures of {hour} hour results.pdf\"))\n",
    "    os.remove(os.path.join(output_folder,f\"ROC of {hour} hour results.pdf\"))\n",
    "    os.remove(os.path.join(output_folder,f\"Results_{hour}hours_scores.txt\"))\n",
    "    os.remove(os.path.join(output_folder,f\"Cal of {hour} hour results.pdf\"))\n",
    "    os.remove(os.path.join(output_folder,f\"Hist of {hour} hour results.pdf\"))\n",
    "    pdf = PdfPages(os.path.join(output_folder,f\"Figures of {hour} hour results.pdf\"))\n",
    "    pdf_ROC= PdfPages(os.path.join(output_folder,f\"ROC of {hour} hour results.pdf\"))\n",
    "    pdf_cal = PdfPages(os.path.join(output_folder,f\"Cal of {hour} hour results.pdf\"))\n",
    "    pdf_hist = PdfPages(os.path.join(output_folder,f\"Hist {hour}  hour results.pdf\"))\n",
    "\n",
    "# loop over different data and feature selection techniques\n",
    "for data_name, xd in zip(data_names, x_data):\n",
    "    # transform columns based on dataframe used\n",
    "    #columns = xd.columns.tolist()\n",
    "    x_train_d = x_train#[columns]\n",
    "    x_test_d = x_test#[columns]\n",
    "    \n",
    "    # Add variable for wrapper based feature selection\n",
    "    if 'Wrap' in data_name:\n",
    "        wrapper += 1\n",
    "    else:\n",
    "        wrapper=0\n",
    "    \n",
    "    # create variables for temp storage lateron\n",
    "    temp_fpr=dict()\n",
    "    temp_tpr=dict()\n",
    "    temp_auc=dict()\n",
    "    temp_probtrue={}\n",
    "    temp_probpred={}\n",
    "    temp_score={}\n",
    "\n",
    "    # loop over different classifiers\n",
    "    for name, clf_s in zip(names, classifiers):\n",
    "\n",
    "        clf,y_pred_clas,y_pred_prob,y_test,x_test_d = machine_learning_function(x_train_d,x_test_d,y_train,y_test,clf_s,wrapper)\n",
    "\n",
    "        # calculate scoring metrics\n",
    "        report=classification_report(y_test,y_pred_clas,target_names=['Alive','Death'])\n",
    "        score=clf.score(x_test_d,y_test)\n",
    "        average_precision = average_precision_score(y_test, y_pred_prob)\n",
    "        f1_s=f1_score(y_test, y_pred_clas)\n",
    "\n",
    "        # write scoring metrics to file\n",
    "        with open(os.path.join(output_folder,f\"Results_{hour}hours_scores.txt\"),'a') as file:\n",
    "            file.write(f\"{data_name} with {name} Results for {hour} hours \\n\\n\")\n",
    "            file.write(f\"Classification report \\n {report} \\n\")\n",
    "            file.write(f\"Hold_out_scores {score} \\n\")\n",
    "            file.write(f\"Average precision score {average_precision} \\n\")\n",
    "            file.write(f\"F1 score {f1_s} \\n\\n\\n\")\n",
    "        \n",
    "        # plot confusion matrix\n",
    "        plot_confusion_matrix(clf,x_test_d,y_test)\n",
    "        plt.title(f\"{data_name} with {name} classifier, Results from {hour} hour data\")\n",
    "        fig=plt.gcf()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # plot ROC with AUC\n",
    "        fpr, tpr, _ = roc_curve(y_test,  y_pred_prob)\n",
    "        auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        plt.plot(fpr,tpr,label=f\"{name}, auc={auc}\")\n",
    "        plt.plot(fpr_pim,tpr_pim,label=f\"PIM3Score, auc={auc_pim}\")\n",
    "        plt.title(f\"{data_name} with {name} classifier, Results from {hour} hour data\")\n",
    "        plt.legend(loc=4)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        fig=plt.gcf()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # temporarly store ROC and AUC per classifier\n",
    "        temp_fpr.update({f'{name}': fpr})\n",
    "        temp_tpr.update({f'{name}': tpr})\n",
    "        temp_auc.update({f'{name}': auc})\n",
    "\n",
    "         # plot callibration plot with brier_loss score\n",
    "        \n",
    "        prob_true, prob_pred = calibration_curve(y_test,  y_pred_prob,normalize=True)\n",
    "        plt.plot(prob_pred,prob_true,label=f\"{name} \")\n",
    "        plt.title(f\"{data_name} with {name} classifier, Results from {hour} hour data\")\n",
    "        plt.legend(loc=4)\n",
    "        plt.ylabel('Fraction of Positives')\n",
    "        fig=plt.gcf()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # temporarly store ROC and AUC per classifier\n",
    "        temp_probtrue.update({f'{name}': prob_true})\n",
    "        temp_probpred.update({f'{name}': prob_pred})\n",
    "        #temp_score.update({f'{name}':clf_score})\n",
    "    \n",
    "        print(f\"{data_name} with {name} classifier, results from {hour} hour data\")\n",
    "        print(\"Original ROC area: {:0.3f}\".format(roc_auc_score(y_test, y_pred_prob)))\n",
    "        print(\"Original ROC area, PIM3: {:0.3f}\".format(roc_auc_score(y_test, x_test['PIM3Score'])))\n",
    "\n",
    "        n_bootstraps = 2000\n",
    "        rng_seed = 42  # control reproducibility\n",
    "        bootstrapped_scores = []\n",
    "\n",
    "        rng = np.random.RandomState(rng_seed)\n",
    "        for i in range(n_bootstraps):\n",
    "            # bootstrap by sampling with replacement on the prediction indices\n",
    "            indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\n",
    "            if len(np.unique(y_test.iloc[indices])) < 2:\n",
    "                # We need at least one positive and one negative sample for ROC AUC\n",
    "                # to be defined: reject the sample\n",
    "                continue\n",
    "\n",
    "            score = roc_auc_score(y_test.iloc[indices], y_pred_prob[indices])\n",
    "            bootstrapped_scores.append(score)\n",
    "            #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\n",
    "\n",
    "        sorted_scores = np.array(bootstrapped_scores)\n",
    "        sorted_scores.sort()\n",
    "\n",
    "        # Computing the lower and upper bound of the 90% confidence interval\n",
    "        # You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "        # a 95% confidence interval instead.\n",
    "        confidence_lower = sorted_scores[int(0.05 * len(sorted_scores))]\n",
    "        confidence_upper = sorted_scores[int(0.95 * len(sorted_scores))]\n",
    "        print(\"Confidence interval for the score: [{:0.3f} - {:0.3}]\".format(\n",
    "            confidence_lower, confidence_upper))\n",
    "        a=roc_auc_ci(y_test,y_pred_prob)\n",
    "        print(a)\n",
    "\n",
    "\n",
    "        \n",
    "    #PLot every roc from the used classifier per feature selection method \n",
    "    a=0\n",
    "    for k,v in temp_fpr.items():\n",
    "        plt.plot(v,temp_tpr.get(k),colours[a],label=f\"{k}, auc={temp_auc.get(k)}\",linewidth=1.5,markersize=1)\n",
    "        np.savetxt(os.path.join(output_folder,f'{k}_fpr_{data_name}_{hour}.csv'),np.asarray(temp_fpr.get(k)),delimiter=';')\n",
    "        np.savetxt(os.path.join(output_folder,f'{k}_tpr_{data_name}_{hour}.csv'),np.asarray(temp_tpr.get(k)),delimiter=';')\n",
    "        a= a+1\n",
    "    plt.plot(fpr_pim,tpr_pim,'b->',label=f\"PIM3Score, auc={auc_pim}\",linewidth=1.5,markersize=1)\n",
    "    plt.legend(loc=4,fontsize='xx-small')\n",
    "    plt.title(f'{data_name} ROC from {hour} hour data')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,1])\n",
    "    axes.set_ylim([0,1])\n",
    "    fig=plt.gcf()\n",
    "    pdf_ROC.savefig(fig)\n",
    "    plt.close(fig)\n",
    "    count=0\n",
    "\n",
    "    #PLot calibration from the used classifier per feature selection method\n",
    "    for k,v in temp_probtrue.items():\n",
    "        plt.plot(temp_probpred.get(k),v,colours[count],label=f\"{k}\",linewidth=1.5,markersize=1)\n",
    "        count += 1\n",
    "    plt.legend(loc=4,fontsize='xx-small')\n",
    "    plt.title(f'{data_name} Calibration Curve from {hour} hour data')\n",
    "    plt.xlabel('Fraction of positives')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,1])\n",
    "    axes.set_ylim([0,1])\n",
    "    fig=plt.gcf()\n",
    "    pdf_cal.savefig(fig)\n",
    "    plt.close(fig)\n",
    "    count=0\n",
    "\n",
    "    # plot histogram from the used classifier per feature selection method\n",
    "    for k,v in temp_probtrue.items():\n",
    "        plt.hist(temp_probpred.get(k),range=(0,1),label=f\"{k}\",histtype='step',lw=2)\n",
    "        count += 1\n",
    "    plt.legend(loc=4,fontsize='xx-small')\n",
    "    plt.title(f'{data_name} Calibration Curve from {hour} hour data')\n",
    "    plt.xlabel('Fraction of positives')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,1])\n",
    "    axes.set_ylim([0,1])\n",
    "    fig=plt.gcf()\n",
    "    pdf_hist.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "    del temp_fpr,temp_tpr,temp_auc\n",
    "pdf.close()\n",
    "pdf_ROC.close()\n",
    "pdf_cal.close()\n",
    "pdf_hist.close()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "# Same functions as before except now specified for Regression algorithms\n",
    "\n",
    "names = [\"Logistic Regression\"\n",
    "        ]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    ]\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=1 / 5)\n",
    "\n",
    "try:\n",
    "    pdf = PdfPages(os.path.join(output_folder,f\"Figures of {hour} hour results_reg.pdf\"))\n",
    "    pdf_ROC= PdfPages(os.path.join(output_folder,f\"ROC of {hour} hour results_regression.pdf\"))\n",
    "except PermissionError:\n",
    "    os.remove(os.path.join(output_folder,f\"ROC of {hour} hour results_regression.pdf\"))\n",
    "    os.remove(os.path.join(output_folder,f\"Figures of {hour} hour results_reg.pdf\"))\n",
    "    os.remove(os.path.join(output_folder,f\"Results_{hour}hours_scores_reg.txt\"))\n",
    "    pdf_ROC= PdfPages(os.path.join(output_folder,f\"ROC of {hour} hour results_regression.pdf\"))\n",
    "    pdf = PdfPages(os.path.join(output_folder,f\"Figures of {hour} hour results_reg.pdf\"))\n",
    "fpr_pim, tpr_pim, _ = roc_curve(y_test,  x_test['PIM3Score'])\n",
    "auc_pim = roc_auc_score(y_test, x_test['PIM3Score'])\n",
    "\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=1 / 5,random_state=1)\n",
    "\n",
    "temp_fpr=dict()\n",
    "temp_tpr=dict()\n",
    "temp_auc=dict()\n",
    "for data_name, xd in zip(data_names, x_data):\n",
    "    # transform columns based on dataframe used\n",
    "    #columns = xd.columns.tolist()\n",
    "    x_train_d = x_train#[columns]\n",
    "    x_test_d = x_test#[columns]\n",
    "    \n",
    "    # Add variable for wrapper based feature selection\n",
    "    if 'Wrap' in data_name:\n",
    "        wrapper += 1\n",
    "    else:\n",
    "        wrapper=0\n",
    "    \n",
    "    # create variables for temp storage lateron\n",
    "    temp_fpr=dict()\n",
    "    temp_tpr=dict()\n",
    "    temp_auc=dict()\n",
    "    temp_probtrue={}\n",
    "    temp_probpred={}\n",
    "    temp_score={}\n",
    "\n",
    "    for name, clf_s in zip(names, classifiers):\n",
    "\n",
    "        clf,y_pred_clas,y_pred_prob,y_test,x_test_d= machine_learning_function(x_train_d,x_test_d,y_train,y_test,clf_s,wrapper)\n",
    "\n",
    "        # calculate scoring metrics\n",
    "        report=classification_report(y_test,y_pred_clas,target_names=['Alive','Death'])\n",
    "        score=clf.score(x_test_d,y_test)\n",
    "        average_precision = average_precision_score(y_test, y_pred_prob)\n",
    "        f1_s=f1_score(y_test, y_pred_clas)\n",
    "\n",
    "        # write scoring metrics to file\n",
    "        with open(os.path.join(output_folder,f\"Results_{hour}hours_scores_reg.txt\"),'a') as file:\n",
    "            file.write(f\"{data_name} with {name} Results for {hour} hours \\n\\n\")\n",
    "            file.write(f\"Classification report \\n {report} \\n\")\n",
    "            file.write(f\"Hold_out_scores {score} \\n\")\n",
    "            file.write(f\"Average precision score {average_precision} \\n\")\n",
    "            file.write(f\"F1 score {f1_s} \\n\\n\\n\")\n",
    "\n",
    "        plot_confusion_matrix(clf,x_test_d,y_test)\n",
    "        plt.title(f\"{data_name} with {name} classifier, Results from {hour} hour data\")\n",
    "        fig=plt.gcf()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test,  y_pred_prob)\n",
    "        auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "\n",
    "        temp_fpr.update({f'{name}': fpr})\n",
    "        temp_tpr.update({f'{name}': tpr})\n",
    "        temp_auc.update({f'{name}': auc})\n",
    "        print(f\"{data_name} with {name} classifier, results from {hour} hour data\")\n",
    "        print(\"Original ROC area: {:0.3f}\".format(roc_auc_score(y_test, y_pred_prob)))\n",
    "        print(\"Original ROC area, PIM3: {:0.3f}\".format(roc_auc_score(y_test, x_test['PIM3Score'])))\n",
    "        n_bootstraps = 2000\n",
    "        rng_seed = 42  # control reproducibility\n",
    "        bootstrapped_scores = []\n",
    "\n",
    "        rng = np.random.RandomState(rng_seed)\n",
    "        for i in range(n_bootstraps):\n",
    "            # bootstrap by sampling with replacement on the prediction indices\n",
    "            indices = rng.randint(0, len(y_pred_prob), len(y_pred_prob))\n",
    "            if len(np.unique(y_test.iloc[indices])) < 2:\n",
    "                # We need at least one positive and one negative sample for ROC AUC\n",
    "                # to be defined: reject the sample\n",
    "                continue\n",
    "\n",
    "            score = roc_auc_score(y_test.iloc[indices], y_pred_prob[indices])\n",
    "            bootstrapped_scores.append(score)\n",
    "            #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\n",
    "\n",
    "        sorted_scores = np.array(bootstrapped_scores)\n",
    "        sorted_scores.sort()\n",
    "\n",
    "        # Computing the lower and upper bound of the 90% confidence interval\n",
    "        # You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "        # a 95% confidence interval instead.\n",
    "        confidence_lower = sorted_scores[int(0.05 * len(sorted_scores))]\n",
    "        confidence_upper = sorted_scores[int(0.95 * len(sorted_scores))]\n",
    "        print(\"Confidence interval for the score: [{:0.3f} - {:0.3}]\".format(\n",
    "            confidence_lower, confidence_upper))\n",
    "        a=roc_auc_ci(y_test,y_pred_prob)\n",
    "        print(a)\n",
    "    a=0\n",
    "    for k,v in temp_fpr.items():\n",
    "        plt.plot(v,temp_tpr.get(k),colours[a],label=f\"{k}, auc={temp_auc.get(k)}\",linewidth=1.5,markersize=1)\n",
    "        np.savetxt(os.path.join(output_folder,f'{k}_fpr_{data_name}_{hour}.csv'),np.asarray(temp_fpr.get(k)),delimiter=';')\n",
    "        np.savetxt(os.path.join(output_folder,f'{k}_tpr_{data_name}_{hour}.csv'),np.asarray(temp_tpr.get(k)),delimiter=';')\n",
    "        a= a+1\n",
    "    plt.plot(fpr_pim,tpr_pim,'b->',label=f\"PIM3Score, auc={auc_pim}\",linewidth=1.5,markersize=1)\n",
    "    plt.legend(loc=4,fontsize='xx-small')\n",
    "    plt.title(f'{name} ROC of {hour} hour data')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,1])\n",
    "    axes.set_ylim([0,1])\n",
    "    fig=plt.gcf()\n",
    "    pdf_ROC.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    del temp_fpr,temp_tpr,temp_auc\n",
    "pdf_ROC.close()\n",
    "pdf.close()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in zip(names,classifiers):\n",
    "    clf,y_pred_clas,y_pred_prob,y_test,x_test_d,float_columns,cat_list= machine_learning_function(x_train_d,x_test_d,y_train,y_test,clf_s,wrapper)\n",
    "    try:\n",
    "        onehot_columns = clf.named_steps['preprocessor'].named_transformers['cat'].named_steps['onehot'].get_feature_names()\n",
    "        #onehot_columns=clf.get_params()['preprocessor__cat__onehot'].get_feature_names(input_features=cat_list)\n",
    "        float_columns.extend(onehot_columns)\n",
    "    except:\n",
    "        print('hello') \n",
    "    try:\n",
    "        coefs = clf.named_steps[\"classifier\"].coef_.flatten()\n",
    "    except:\n",
    "        coefs=clf.named_steps[\"classifier\"].feature_importances_\n",
    "    import pandas as pd\n",
    "    # Zip coefficients and names together and make a DataFrame\n",
    "    zipped = zip(float_columns, coefs)\n",
    "    df = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "    # Sort the features by the absolute value of their coefficient\n",
    "    df[\"abs_value\"] = df[\"value\"].apply(lambda x: abs(x))\n",
    "    df[\"colors\"] = df[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "    df = df.sort_values(\"abs_value\", ascending=False)\n",
    "\n",
    "\n",
    "    import seaborn as sns\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 4))\n",
    "    sns.barplot(x=\"feature\",\n",
    "                y=\"value\",\n",
    "                data=df.head(30),\n",
    "                palette=df.head(30)[\"colors\"])\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=12)\n",
    "    ax.set_title(f\"Top 20 Features, {data_name},{names},{classifiers}\", fontsize=12)\n",
    "    ax.set_ylabel(\"Coef\", fontsize=12)\n",
    "    ax.set_xlabel(\"Feature Name\", fontsize=12)\n",
    "\n",
    "    print(df[\"feature\"].head(20).tolist())"
   ]
  }
 ]
}